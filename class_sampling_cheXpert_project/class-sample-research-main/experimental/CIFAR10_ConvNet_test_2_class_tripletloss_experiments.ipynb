{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c3c2891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "from warnings import simplefilter\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "378c3ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import class_sampling\n",
    "import train\n",
    "import metric_utils\n",
    "import inference\n",
    "import loss_fns\n",
    "import torchvision.ops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91dda12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "n_epochs = 30\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "momentum = 0\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "NUM_CLASSES_REDUCED = 2\n",
    "nums = (0, 1)\n",
    "ratio = (100, 1)\n",
    "\n",
    "CLASS_LABELS = {'airplane': 0,\n",
    "                 'automobile': 1,\n",
    "                 'bird': 2,\n",
    "                 'cat': 3,\n",
    "                 'deer': 4,\n",
    "                 'dog': 5,\n",
    "                 'frog': 6,\n",
    "                 'horse': 7,\n",
    "                 'ship': 8,\n",
    "                 'truck': 9}\n",
    "\n",
    "\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b57e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"name\", \n",
    "            \"num_classes\", \n",
    "            \"classes_used\", \n",
    "            \"ratio\", \n",
    "            \"learning_rate\", \n",
    "            \"mean_0\", \"variance_0\",\n",
    "            \"mean_10\", \"variance_10\",\n",
    "            \"mean_20\", \"variance_20\",\n",
    "            \"mean_30\", \"variance_30\",\n",
    "          #   \"mean_40\", \"variance_40\",\n",
    "          #   \"mean_50\", \"variance_50\",\n",
    "             \"cap\", \"normalization\", \"other\"]\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c2a1ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "norm=False\n",
    "\n",
    "if norm:\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.Normalize(mean=[143.8888, 127.1705, 117.5357], std=[69.8313, 64.5137, 66.9933])])\n",
    "else:\n",
    "   # transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "    transform=None\n",
    "\n",
    "train_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=True, download=True,\n",
    "                             transform=transform)  \n",
    "\n",
    "\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10('cifar10', train=False, download=True,\n",
    "                             transform=transform)  \n",
    "\n",
    "train_CIFAR10.data = train_CIFAR10.data.reshape(50000, 3, 32, 32)\n",
    "test_CIFAR10.data = test_CIFAR10.data.reshape(10000, 3, 32, 32)\n",
    "\n",
    "    \n",
    "reduced_train_CIFAR10 = class_sampling.Reduce(train_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True, transform=transform)\n",
    "reduced_test_CIFAR10 = class_sampling.Reduce(test_CIFAR10, NUM_CLASSES_REDUCED, nums=nums, CIFAR=True, transform=transform)\n",
    "\n",
    "ratio_train_CIFAR10 = class_sampling.Ratio(train_CIFAR10, NUM_CLASSES_REDUCED, ratio, nums=nums, transform=transform)\n",
    "\n",
    "triplet_train_CIFAR10 = class_sampling.ForTripletLoss(reduced_train_CIFAR10, smote=False, transform=transform, num_classes=2)\n",
    "triplet_ratio_train_CIFAR10 = class_sampling.ForTripletLoss(ratio_train_CIFAR10, smote=False, transform=transform, num_classes=2)\n",
    "\n",
    "smote_train_CIFAR10 = class_sampling.Smote(ratio_train_CIFAR10, 5000 * NUM_CLASSES_REDUCED, transform=transform)\n",
    "triplet_smote_train_CIFAR10 = class_sampling.ForTripletLoss(smote_train_CIFAR10, smote=True, transform=transform, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13159c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000   50]\n"
     ]
    }
   ],
   "source": [
    "targets = ratio_train_CIFAR10.labels \n",
    "\n",
    "class_count = np.unique(targets, return_counts=True)[1]\n",
    "print(class_count)\n",
    "\n",
    "weight = 1. / class_count\n",
    "\n",
    "samples_weight = weight[targets]\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "oversampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(max(class_count) * NUM_CLASSES_REDUCED), replacement=True)\n",
    "sampler = torch.utils.data.WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)\n",
    "undersampler = torch.utils.data.WeightedRandomSampler(samples_weight, int(min(class_count) * NUM_CLASSES_REDUCED), replacement=False)\n",
    "undersampler_smote = torch.utils.data.WeightedRandomSampler(samples_weight, int(min(class_count) * 50 * NUM_CLASSES_REDUCED), replacement=False)\n",
    "weight *= class_count[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af8cd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_CIFAR10, batch_size=batch_size_train, shuffle=True)  \n",
    "\n",
    "train_loader_reduced = DataLoader(reduced_train_CIFAR10, batch_size=batch_size_train, shuffle=True)  \n",
    "\n",
    "train_loader_ratio = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, shuffle=True) \n",
    "\n",
    "train_loader_oversampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=oversampler)\n",
    "\n",
    "train_loader_undersampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=undersampler)\n",
    "\n",
    "train_loader_sampled = DataLoader(ratio_train_CIFAR10, batch_size=batch_size_train, sampler=sampler)\n",
    "\n",
    "train_loader_smote = DataLoader(smote_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "train_loader_smote_undersampled = DataLoader(smote_train_CIFAR10, batch_size=batch_size_train, sampler=undersampler_smote)\n",
    "\n",
    "train_loader_tripletloss = DataLoader(triplet_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "train_loader_tripletloss_ratio = DataLoader(triplet_ratio_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "train_loader_tripletloss_smote = DataLoader(triplet_smote_train_CIFAR10, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader_reduced = DataLoader(reduced_test_CIFAR10, batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a9137b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used in distance capped smote - get average tensor for the entire class \n",
    "dataset = train_loader_ratio.dataset\n",
    "class0 = dataset.images[dataset.labels==0]\n",
    "class1 = dataset.images[dataset.labels==1]\n",
    "class0_avg = torch.mean(class0.float(), 0)\n",
    "class1_avg = torch.mean(class1.float(), 0)\n",
    "class_img_list = [class0, class1]\n",
    "avg_tensors_list = [class0_avg, class1_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "def5b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006935921907424927, AUC: 0.49950249999999996\n",
      "\n",
      "Train loss: 2.177517574683876\n",
      "Train loss: 1.6380580819336472\n",
      "Train loss: 1.1406405074581218\n",
      "Train loss: 0.7840143058710037\n",
      "Train loss: 0.6454909557749511\n",
      "Train loss: 0.6736217581542434\n",
      "Train loss: 0.5023672933791093\n",
      "\n",
      "Test set: Avg. loss: 0.0005835582911968231, AUC: 0.82512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009920628368854524, AUC: 0.8249149999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012335069775581359, AUC: 0.825456\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006931573152542114, AUC: 0.500922\n",
      "\n",
      "Train loss: 1.6729937947479783\n",
      "Train loss: 1.2497364237050341\n",
      "Train loss: 1.4129337026814746\n",
      "Train loss: 0.8325555635865327\n",
      "Train loss: 0.8456783746458163\n",
      "Train loss: 0.6941262654438141\n",
      "Train loss: 0.4846640954351729\n",
      "\n",
      "Test set: Avg. loss: 0.0005466402471065522, AUC: 0.834989\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006964411139488221, AUC: 0.864082\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011362184882164, AUC: 0.8568830000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006933403015136719, AUC: 0.4912249999999999\n",
      "\n",
      "Train loss: 1.3286936146438502\n",
      "Train loss: 1.0818881794905206\n",
      "Train loss: 0.7524862243871021\n",
      "Train loss: 0.6287265769235647\n",
      "Train loss: 0.8437562672195921\n",
      "Train loss: 0.4807655902425195\n",
      "Train loss: 0.5578409664949794\n",
      "\n",
      "Test set: Avg. loss: 0.0005730546712875367, AUC: 0.8327929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005311442613601684, AUC: 0.8972399999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010285172462463378, AUC: 0.856297\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006993223130702973, AUC: 0.3149995\n",
      "\n",
      "Train loss: 1.6903990651391874\n",
      "Train loss: 1.1460003006230495\n",
      "Train loss: 1.0459204202244996\n",
      "Train loss: 0.7239399442247524\n",
      "Train loss: 0.805482519280379\n",
      "Train loss: 0.8252812157011336\n",
      "Train loss: 0.6473919103859337\n",
      "\n",
      "Test set: Avg. loss: 0.0005199187099933625, AUC: 0.842812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008001270592212677, AUC: 0.8832609999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010325151681900024, AUC: 0.878194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006948794424533844, AUC: 0.47467650000000006\n",
      "\n",
      "Train loss: 0.8718358244106268\n",
      "Train loss: 0.9390531436652895\n",
      "Train loss: 0.5551516618698266\n",
      "Train loss: 0.5036967149965322\n",
      "Train loss: 0.5064410206618583\n",
      "Train loss: 0.3864659139305163\n",
      "Train loss: 0.3710649191953574\n",
      "\n",
      "Test set: Avg. loss: 0.0006033060848712921, AUC: 0.8079050000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009136085212230683, AUC: 0.854994\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011147674322128296, AUC: 0.8595890000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006928186416625976, AUC: 0.5812449999999999\n",
      "\n",
      "Train loss: 0.9429198287095234\n",
      "Train loss: 0.8842787829933653\n",
      "Train loss: 0.5132170460026735\n",
      "Train loss: 0.5555504047946566\n",
      "Train loss: 0.4351699724318875\n",
      "Train loss: 0.5145767042591314\n",
      "Train loss: 0.25995148253288997\n",
      "\n",
      "Test set: Avg. loss: 0.0005589176416397095, AUC: 0.815986\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009041883945465087, AUC: 0.71625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001572501540184021, AUC: 0.8323365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006953505873680115, AUC: 0.43955099999999997\n",
      "\n",
      "Train loss: 2.1179291389550374\n",
      "Train loss: 1.564866894369672\n",
      "Train loss: 0.8822338789891285\n",
      "Train loss: 0.834831382058988\n",
      "Train loss: 0.847092204412837\n",
      "Train loss: 0.5720949962640264\n",
      "Train loss: 0.46107340048832496\n",
      "\n",
      "Test set: Avg. loss: 0.0005538147091865539, AUC: 0.8174159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000726842850446701, AUC: 0.857922\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001072457492351532, AUC: 0.8572789999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006906655728816986, AUC: 0.5943860000000001\n",
      "\n",
      "Train loss: 0.6617238601301886\n",
      "Train loss: 1.2583209853263417\n",
      "Train loss: 0.9339834098603316\n",
      "Train loss: 0.8755108767254337\n",
      "Train loss: 0.7299662839834857\n",
      "Train loss: 0.5094438605247789\n",
      "Train loss: 0.5751960391451598\n",
      "\n",
      "Test set: Avg. loss: 0.0005459891855716705, AUC: 0.834536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009487561583518981, AUC: 0.8491349999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010010668635368348, AUC: 0.856897\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006863009333610534, AUC: 0.7181944999999998\n",
      "\n",
      "Train loss: 1.3030771362553737\n",
      "Train loss: 1.367749709612245\n",
      "Train loss: 1.1171545029445817\n",
      "Train loss: 1.0733120187072998\n",
      "Train loss: 0.6321681198800445\n",
      "Train loss: 0.422201008933365\n",
      "Train loss: 0.3547062213253823\n",
      "\n",
      "Test set: Avg. loss: 0.0005816086530685424, AUC: 0.7956259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008047966063022613, AUC: 0.869351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006690053343772888, AUC: 0.8801065\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006977859139442444, AUC: 0.39963499999999996\n",
      "\n",
      "Train loss: 1.4583385856288253\n",
      "Train loss: 1.0722816651034508\n",
      "Train loss: 1.0319720726863595\n",
      "Train loss: 1.0311277561886296\n",
      "Train loss: 1.2621329012949756\n",
      "Train loss: 0.9534358340463821\n",
      "Train loss: 0.8318366548817628\n",
      "\n",
      "Test set: Avg. loss: 0.00055805703997612, AUC: 0.815993\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008911563754081726, AUC: 0.836491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011183717846870423, AUC: 0.8461620000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006952802836894989, AUC: 0.46065350000000005\n",
      "\n",
      "Train loss: 1.3724136834691285\n",
      "Train loss: 1.3019905242190999\n",
      "Train loss: 1.4970016707280638\n",
      "Train loss: 1.3051228394174272\n",
      "Train loss: 1.4305963527624774\n",
      "Train loss: 1.597745087875682\n",
      "Train loss: 1.1283231559832385\n",
      "\n",
      "Test set: Avg. loss: 0.0006305583417415618, AUC: 0.7962429999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000692214161157608, AUC: 0.855658\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007845332026481628, AUC: 0.8640100000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006915698349475861, AUC: 0.6975370000000001\n",
      "\n",
      "Train loss: 0.8625301164426621\n",
      "Train loss: 0.6896624584106883\n",
      "Train loss: 0.9616624750908772\n",
      "Train loss: 0.876757461553926\n",
      "Train loss: 0.6730601742009449\n",
      "Train loss: 0.7759512731224109\n",
      "Train loss: 0.9313772632058259\n",
      "\n",
      "Test set: Avg. loss: 0.000629446029663086, AUC: 0.7844980000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929272413253784, AUC: 0.852044\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008184383511543274, AUC: 0.846831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006933963298797608, AUC: 0.5625225\n",
      "\n",
      "Train loss: 2.582062100149264\n",
      "Train loss: 3.1241754597159708\n",
      "Train loss: 2.1176407306816927\n",
      "Train loss: 1.7143658035120386\n",
      "Train loss: 1.9715968867775742\n",
      "Train loss: 1.640156652137732\n",
      "Train loss: 1.3952363490299056\n",
      "\n",
      "Test set: Avg. loss: 0.0005751769840717316, AUC: 0.7867200000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007662321031093597, AUC: 0.8479059999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008849923014640808, AUC: 0.845101\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006976578831672668, AUC: 0.3424385\n",
      "\n",
      "Train loss: 2.0492958039235156\n",
      "Train loss: 1.6887284384411612\n",
      "Train loss: 1.8092068578027616\n",
      "Train loss: 1.5915723701191555\n",
      "Train loss: 1.5888339076072546\n",
      "Train loss: 1.670342746054291\n",
      "Train loss: 1.4874985278791684\n",
      "\n",
      "Test set: Avg. loss: 0.0005804129540920257, AUC: 0.793558\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000661219984292984, AUC: 0.84292\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000726669192314148, AUC: 0.874074\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006921343803405762, AUC: 0.6028100000000001\n",
      "\n",
      "Train loss: 1.5102111776922917\n",
      "Train loss: 1.3182463380181866\n",
      "Train loss: 1.3701547300739654\n",
      "Train loss: 1.0832740804951662\n",
      "Train loss: 1.5650673444104042\n",
      "Train loss: 1.2147834790740044\n",
      "Train loss: 1.014148785430155\n",
      "\n",
      "Test set: Avg. loss: 0.0006008230149745942, AUC: 0.780478\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007142759561538696, AUC: 0.846722\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008143155872821808, AUC: 0.8590550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006868746578693389, AUC: 0.7377745\n",
      "\n",
      "Train loss: 0.35443028371045543\n",
      "Train loss: 0.3987295783249436\n",
      "Train loss: 0.4841962661712792\n",
      "Train loss: 0.6026698138303818\n",
      "Train loss: 0.5660832197802841\n",
      "Train loss: 0.15341077488698776\n",
      "Train loss: 0.3904989650295039\n",
      "\n",
      "Test set: Avg. loss: 0.0006066063642501831, AUC: 0.78793\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006299271285533905, AUC: 0.8624120000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009019392728805542, AUC: 0.8715729999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006894753873348237, AUC: 0.668938\n",
      "\n",
      "Train loss: 1.64597365658754\n",
      "Train loss: 1.6885060899576563\n",
      "Train loss: 1.5479867693724905\n",
      "Train loss: 1.224408593527071\n",
      "Train loss: 1.262662738751454\n",
      "Train loss: 0.840511354291515\n",
      "Train loss: 1.0778432089811678\n",
      "\n",
      "Test set: Avg. loss: 0.0005716147124767303, AUC: 0.7869550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000718360811471939, AUC: 0.692191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010487006306648253, AUC: 0.8398259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006995047628879547, AUC: 0.23771199999999998\n",
      "\n",
      "Train loss: 1.260247220279305\n",
      "Train loss: 1.3323008550959787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2180204220638153\n",
      "Train loss: 0.9437161213273455\n",
      "Train loss: 1.1438231540333694\n",
      "Train loss: 1.0984935316310567\n",
      "Train loss: 0.9357851470351979\n",
      "\n",
      "Test set: Avg. loss: 0.000600229024887085, AUC: 0.7645534999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005565653443336487, AUC: 0.862451\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008587767779827118, AUC: 0.863323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006796721220016479, AUC: 0.6995895000000001\n",
      "\n",
      "Train loss: 0.9809628584582335\n",
      "Train loss: 1.484111073670114\n",
      "Train loss: 1.4938363877071696\n",
      "Train loss: 1.3425806813938603\n",
      "Train loss: 0.9585896707644128\n",
      "Train loss: 1.0558493873875612\n",
      "Train loss: 0.8446820545348392\n",
      "\n",
      "Test set: Avg. loss: 0.000575296938419342, AUC: 0.789242\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006668233573436737, AUC: 0.8551500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000939850389957428, AUC: 0.8261339999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006948827803134918, AUC: 0.4687185\n",
      "\n",
      "Train loss: 0.8151624411534352\n",
      "Train loss: 0.629118713983305\n",
      "Train loss: 0.9305645246414622\n",
      "Train loss: 0.9890331333609903\n",
      "Train loss: 1.172149836637412\n",
      "Train loss: 0.7481742053274896\n",
      "Train loss: 0.9584673441899051\n",
      "\n",
      "Test set: Avg. loss: 0.0006056396663188934, AUC: 0.815732\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007121290266513824, AUC: 0.864198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008230615258216858, AUC: 0.8630490000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007006746828556061, AUC: 0.381764\n",
      "\n",
      "Train loss: 4.002087337196253\n",
      "Train loss: 4.999213933565055\n",
      "Train loss: 4.291623610220138\n",
      "Train loss: 3.3078236849444687\n",
      "Train loss: 2.654596774061774\n",
      "Train loss: 3.0889571559656956\n",
      "Train loss: 2.9014591160853196\n",
      "\n",
      "Test set: Avg. loss: 0.0005679965317249298, AUC: 0.8132840000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008065813779830933, AUC: 0.863116\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007893595993518829, AUC: 0.876382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007008528411388398, AUC: 0.32213349999999996\n",
      "\n",
      "Train loss: 1.3353144537871051\n",
      "Train loss: 1.1807025773510051\n",
      "Train loss: 1.3065783825649577\n",
      "Train loss: 1.5465411437544854\n",
      "Train loss: 1.1878419928489976\n",
      "Train loss: 1.2757600025766214\n",
      "Train loss: 1.2938019257442208\n",
      "\n",
      "Test set: Avg. loss: 0.0005734370648860931, AUC: 0.8218260000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008284166753292084, AUC: 0.871235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007242268919944763, AUC: 0.8742380000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006949720978736878, AUC: 0.5585475\n",
      "\n",
      "Train loss: 1.785218388791297\n",
      "Train loss: 1.5590556544862735\n",
      "Train loss: 1.2506017931707345\n",
      "Train loss: 1.0820047779447715\n",
      "Train loss: 1.035564358447008\n",
      "Train loss: 1.1756351624324823\n",
      "Train loss: 0.7142437666085115\n",
      "\n",
      "Test set: Avg. loss: 0.0005533872842788697, AUC: 0.845419\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007064732313156128, AUC: 0.852571\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010236549377441407, AUC: 0.866529\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006998100280761718, AUC: 0.374729\n",
      "\n",
      "Train loss: 2.975822244859805\n",
      "Train loss: 2.1248649115775042\n",
      "Train loss: 1.7734096551397045\n",
      "Train loss: 2.347869396589364\n",
      "Train loss: 2.3442162089287097\n",
      "Train loss: 1.598779011683859\n",
      "Train loss: 1.793307822601051\n",
      "\n",
      "Test set: Avg. loss: 0.0005254692137241363, AUC: 0.842522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000975600004196167, AUC: 0.8367639999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011257168650627136, AUC: 0.8579479999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006937425136566162, AUC: 0.5113590000000001\n",
      "\n",
      "Train loss: 1.0699153834847128\n",
      "Train loss: 1.0995471325649577\n",
      "Train loss: 1.0438232991346128\n",
      "Train loss: 1.0568871638577455\n",
      "Train loss: 0.9990578802527895\n",
      "Train loss: 0.8411721617552885\n",
      "Train loss: 0.9457434772685834\n",
      "\n",
      "Test set: Avg. loss: 0.0005800670683383942, AUC: 0.807429\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013021867275238037, AUC: 0.795782\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014482392072677612, AUC: 0.832317\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006968962252140045, AUC: 0.35146550000000004\n",
      "\n",
      "Train loss: 3.271517605538581\n",
      "Train loss: 2.865010929715102\n",
      "Train loss: 2.6551452677720673\n",
      "Train loss: 2.6943643639801413\n",
      "Train loss: 2.3062556427755174\n",
      "Train loss: 2.030261951646987\n",
      "Train loss: 1.1780780398162307\n",
      "\n",
      "Test set: Avg. loss: 0.0005371105372905731, AUC: 0.835083\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007857041358947754, AUC: 0.8609370000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015919213891029357, AUC: 0.8177540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006972049474716186, AUC: 0.524102\n",
      "\n",
      "Train loss: 1.1673677225781094\n",
      "Train loss: 0.8010970395841416\n",
      "Train loss: 1.2556147955025836\n",
      "Train loss: 0.8760187994143006\n",
      "Train loss: 1.0721359082088349\n",
      "Train loss: 0.9524844888668911\n",
      "Train loss: 0.8836633749068923\n",
      "\n",
      "Test set: Avg. loss: 0.000583396852016449, AUC: 0.8282590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011342144012451171, AUC: 0.8370770000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001054746687412262, AUC: 0.8714809999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006993263065814972, AUC: 0.37520300000000006\n",
      "\n",
      "Train loss: 3.3376090222862875\n",
      "Train loss: 4.196661624938819\n",
      "Train loss: 3.6199083540849624\n",
      "Train loss: 4.753478425703231\n",
      "Train loss: 3.38244118204542\n",
      "Train loss: 4.134634631074918\n",
      "Train loss: 3.0703558621892504\n",
      "\n",
      "Test set: Avg. loss: 0.0005853714346885681, AUC: 0.8141179999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007846144437789917, AUC: 0.8496410000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008569560647010803, AUC: 0.851914\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007004051506519318, AUC: 0.2847315\n",
      "\n",
      "Train loss: 1.0372308914069157\n",
      "Train loss: 1.324387824079793\n",
      "Train loss: 1.2924554982003134\n",
      "Train loss: 0.9679160778689536\n",
      "Train loss: 0.7014027013900174\n",
      "Train loss: 0.991824774225806\n",
      "Train loss: 1.3211248611948292\n",
      "\n",
      "Test set: Avg. loss: 0.000602714866399765, AUC: 0.8090609999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010694165229797362, AUC: 0.8079700000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015938061475753785, AUC: 0.8306755000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006862429082393647, AUC: 0.7057755\n",
      "\n",
      "Train loss: 2.884517780155133\n",
      "Train loss: 2.3535300793161817\n",
      "Train loss: 1.9088799433343728\n",
      "Train loss: 1.476317778514449\n",
      "Train loss: 1.654255051901386\n",
      "Train loss: 1.5776490910797363\n",
      "Train loss: 1.7961316678174741\n",
      "\n",
      "Test set: Avg. loss: 0.001948243796825409, AUC: 0.29143699999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001239864706993103, AUC: 0.43233\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009613255262374878, AUC: 0.804338\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006936465501785279, AUC: 0.4811405\n",
      "\n",
      "Train loss: 1.4519355000963636\n",
      "Train loss: 1.515168170640423\n",
      "Train loss: 0.8029084346096986\n",
      "Train loss: 0.8137372629657672\n",
      "Train loss: 0.4668187142177752\n",
      "Train loss: 0.3705952262422841\n",
      "Train loss: 0.19993587170436883\n",
      "\n",
      "Test set: Avg. loss: 0.0012195956110954286, AUC: 0.843382\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017624920606613159, AUC: 0.7836304999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022736542224884035, AUC: 0.8269580000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007018917500972748, AUC: 0.2993885\n",
      "\n",
      "Train loss: 2.604000561556239\n",
      "Train loss: 1.9376326423541756\n",
      "Train loss: 1.0117976927453545\n",
      "Train loss: 1.3443316760336517\n",
      "Train loss: 0.7446878768835857\n",
      "Train loss: 0.44707257125028377\n",
      "Train loss: 0.7358623496286428\n",
      "\n",
      "Test set: Avg. loss: 0.00092985999584198, AUC: 0.812104\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001912372052669525, AUC: 0.8607989999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002147028923034668, AUC: 0.8316295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943816542625427, AUC: 0.434986\n",
      "\n",
      "Train loss: 1.2383678627621597\n",
      "Train loss: 1.6285360869328687\n",
      "Train loss: 1.0507018642061074\n",
      "Train loss: 0.7026162041220695\n",
      "Train loss: 1.0633667065839099\n",
      "Train loss: 1.1298323330605866\n",
      "Train loss: 0.58818879780496\n",
      "\n",
      "Test set: Avg. loss: 0.000684097409248352, AUC: 0.8305135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011867043972015382, AUC: 0.5897954999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0032673325538635253, AUC: 0.5245465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000693394809961319, AUC: 0.5271899999999999\n",
      "\n",
      "Train loss: 0.8538646792909902\n",
      "Train loss: 0.8679394885233254\n",
      "Train loss: 0.9318104469852083\n",
      "Train loss: 0.7509367226795026\n",
      "Train loss: 0.4448609910193522\n",
      "Train loss: 0.3341198730620609\n",
      "Train loss: 0.4822718246727233\n",
      "\n",
      "Test set: Avg. loss: 0.0007635962665081024, AUC: 0.8403695000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017326134443283081, AUC: 0.828704\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018567978739738465, AUC: 0.8826625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006913981437683106, AUC: 0.6688244999999999\n",
      "\n",
      "Train loss: 0.9127137972291108\n",
      "Train loss: 0.6158442990795062\n",
      "Train loss: 0.577678885429528\n",
      "Train loss: 0.3091191493781509\n",
      "Train loss: 0.40245697908340744\n",
      "Train loss: 0.5405659159277655\n",
      "Train loss: 0.6191547121971276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0005970579981803894, AUC: 0.87058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001575674593448639, AUC: 0.5713649999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021874072551727295, AUC: 0.850484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006925201416015625, AUC: 0.6156795\n",
      "\n",
      "Train loss: 0.9343462924289095\n",
      "Train loss: 0.6148989853585601\n",
      "Train loss: 0.44618014127585537\n",
      "Train loss: 0.4370109970402566\n",
      "Train loss: 0.2451456701679594\n",
      "Train loss: 0.236677428339697\n",
      "Train loss: 0.4134507080551925\n",
      "\n",
      "Test set: Avg. loss: 0.0006584177911281585, AUC: 0.858113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001124662458896637, AUC: 0.8633175000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019451584815979004, AUC: 0.85242\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006994863748550415, AUC: 0.31585050000000003\n",
      "\n",
      "Train loss: 3.351314946344704\n",
      "Train loss: 2.988919793040889\n",
      "Train loss: 1.928568492649467\n",
      "Train loss: 1.624183717047333\n",
      "Train loss: 1.2383005167268644\n",
      "Train loss: 0.948305770849726\n",
      "Train loss: 1.1118718298377506\n",
      "\n",
      "Test set: Avg. loss: 0.0008737375140190124, AUC: 0.8097720000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021728287935256956, AUC: 0.834549\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0024115344285964967, AUC: 0.8231679999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006965971887111663, AUC: 0.45992900000000003\n",
      "\n",
      "Train loss: 1.7906300493866016\n",
      "Train loss: 1.1643340974856333\n",
      "Train loss: 1.1664838392263766\n",
      "Train loss: 1.3188717334893099\n",
      "Train loss: 0.6068183176077095\n",
      "Train loss: 0.7531826222778126\n",
      "Train loss: 0.7188182981910219\n",
      "\n",
      "Test set: Avg. loss: 0.0008517376184463501, AUC: 0.8800209999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019066178798675538, AUC: 0.8311785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022220959663391115, AUC: 0.868596\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006930149197578431, AUC: 0.5297189999999999\n",
      "\n",
      "Train loss: 2.1465846303921596\n",
      "Train loss: 1.002404780904199\n",
      "Train loss: 1.1475565342386818\n",
      "Train loss: 0.7267441259827584\n",
      "Train loss: 0.752424533959407\n",
      "Train loss: 0.5985183723413261\n",
      "Train loss: 0.3659177411134076\n",
      "\n",
      "Test set: Avg. loss: 0.0006396990418434143, AUC: 0.8915710000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018826068639755248, AUC: 0.855995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023861531019210816, AUC: 0.8291529999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006957076787948609, AUC: 0.39958650000000007\n",
      "\n",
      "Train loss: 1.9639354234288453\n",
      "Train loss: 1.3931539506669257\n",
      "Train loss: 1.241314181856289\n",
      "Train loss: 0.7841972105062691\n",
      "Train loss: 0.7592042623811467\n",
      "Train loss: 0.5291420711073905\n",
      "Train loss: 0.6300029982427123\n",
      "\n",
      "Test set: Avg. loss: 0.0006414931714534759, AUC: 0.785207\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014570218920707703, AUC: 0.863677\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023862175941467287, AUC: 0.8798069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007000769078731537, AUC: 0.3001145\n",
      "\n",
      "Train loss: 1.9363996656077682\n",
      "Train loss: 1.6803116441532304\n",
      "Train loss: 1.65254948093633\n",
      "Train loss: 0.8281272080293887\n",
      "Train loss: 1.085215613340876\n",
      "Train loss: 0.9112305500704772\n",
      "Train loss: 0.6924269267707873\n",
      "\n",
      "Test set: Avg. loss: 0.0005656218826770782, AUC: 0.820816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008143361806869507, AUC: 0.864957\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011232481598854064, AUC: 0.856406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006921387016773224, AUC: 0.5802095\n",
      "\n",
      "Train loss: 1.3113749820715304\n",
      "Train loss: 1.1495024436598371\n",
      "Train loss: 0.9351212629087412\n",
      "Train loss: 0.5377032889682016\n",
      "Train loss: 0.5403034185907644\n",
      "Train loss: 0.48900340696808636\n",
      "Train loss: 0.4541932272303636\n",
      "\n",
      "Test set: Avg. loss: 0.0005707074403762817, AUC: 0.83395\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009258108735084534, AUC: 0.861599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014520744681358337, AUC: 0.80473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007046191096305847, AUC: 0.352437\n",
      "\n",
      "Train loss: 1.2357532025142839\n",
      "Train loss: 1.7098666030889864\n",
      "Train loss: 1.1828158934404895\n",
      "Train loss: 0.8618565494087851\n",
      "Train loss: 0.6547605004280236\n",
      "Train loss: 0.8275287861277343\n",
      "Train loss: 0.6491281401579547\n",
      "\n",
      "Test set: Avg. loss: 0.0005583318769931793, AUC: 0.81446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008167432248592377, AUC: 0.87785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008206913173198699, AUC: 0.885616\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006959875822067261, AUC: 0.40752150000000004\n",
      "\n",
      "Train loss: 0.793331019058349\n",
      "Train loss: 0.5125817489472164\n",
      "Train loss: 0.8192166503827283\n",
      "Train loss: 0.6423608755609792\n",
      "Train loss: 0.6340023169092311\n",
      "Train loss: 0.42418927030198894\n",
      "Train loss: 0.4345615635252303\n",
      "\n",
      "Test set: Avg. loss: 0.0005426744818687438, AUC: 0.833774\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006547262072563171, AUC: 0.8702749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015797108411788941, AUC: 0.8385239999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006919906437397003, AUC: 0.5482415\n",
      "\n",
      "Train loss: 2.779289529581738\n",
      "Train loss: 2.4670045436567563\n",
      "Train loss: 2.4955690400615618\n",
      "Train loss: 1.6636859201321936\n",
      "Train loss: 1.0739074535430617\n",
      "Train loss: 0.907081848496844\n",
      "Train loss: 0.728489004882278\n",
      "\n",
      "Test set: Avg. loss: 0.0005925931930541992, AUC: 0.817359\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009105324447154999, AUC: 0.847351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009632153511047363, AUC: 0.8767759999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006988109052181244, AUC: 0.2903135\n",
      "\n",
      "Train loss: 2.2299764494227756\n",
      "Train loss: 1.273984429562927\n",
      "Train loss: 0.9711828622848365\n",
      "Train loss: 1.077061447368306\n",
      "Train loss: 0.7615220466996454\n",
      "Train loss: 0.8190627963679611\n",
      "Train loss: 0.6386881307431846\n",
      "\n",
      "Test set: Avg. loss: 0.0005456936359405517, AUC: 0.83408\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006822890937328339, AUC: 0.861472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009825220704078675, AUC: 0.8766629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006972229480743408, AUC: 0.4133195\n",
      "\n",
      "Train loss: 1.335662146662451\n",
      "Train loss: 1.3771059862367667\n",
      "Train loss: 0.8767685419434954\n",
      "Train loss: 0.7040400740447318\n",
      "Train loss: 0.6166709779174464\n",
      "Train loss: 0.586402639082283\n",
      "Train loss: 0.48365926818483196\n",
      "\n",
      "Test set: Avg. loss: 0.000553589016199112, AUC: 0.832657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008725796341896057, AUC: 0.871448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009293519854545593, AUC: 0.8891659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006929084360599518, AUC: 0.668336\n",
      "\n",
      "Train loss: 1.2443175767637362\n",
      "Train loss: 1.2029382423230797\n",
      "Train loss: 0.7362865703121112\n",
      "Train loss: 0.7496349633119668\n",
      "Train loss: 0.44380610801611736\n",
      "Train loss: 0.6538058071379449\n",
      "Train loss: 0.6055360428846566\n",
      "\n",
      "Test set: Avg. loss: 0.00057013139128685, AUC: 0.811887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012290835976600646, AUC: 0.7518305\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001582571804523468, AUC: 0.800854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006903566718101502, AUC: 0.6254554999999999\n",
      "\n",
      "Train loss: 1.673681598560066\n",
      "Train loss: 0.9801043272018433\n",
      "Train loss: 0.9530287221738487\n",
      "Train loss: 0.651317759683937\n",
      "Train loss: 0.8123658477880393\n",
      "Train loss: 0.3636787822292109\n",
      "Train loss: 0.28137314927046464\n",
      "\n",
      "Test set: Avg. loss: 0.0005769862234592438, AUC: 0.8275359999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010096140503883361, AUC: 0.8447089999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006806451380252838, AUC: 0.882293\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006975733935832977, AUC: 0.4111945\n",
      "\n",
      "Train loss: 1.9254487707356738\n",
      "Train loss: 1.3670317352197732\n",
      "Train loss: 0.7181698907712463\n",
      "Train loss: 0.9530384567133181\n",
      "Train loss: 0.5597833637978621\n",
      "Train loss: 0.6541422567549785\n",
      "Train loss: 0.5455137867077141\n",
      "\n",
      "Test set: Avg. loss: 0.0005724069476127625, AUC: 0.825422\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011023877263069152, AUC: 0.514187\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007668513357639312, AUC: 0.8755520000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006944189071655273, AUC: 0.5222265\n",
      "\n",
      "Train loss: 2.421320586447503\n",
      "Train loss: 1.798823517978571\n",
      "Train loss: 2.286185460105823\n",
      "Train loss: 1.9458639720442947\n",
      "Train loss: 1.62435266698242\n",
      "Train loss: 1.3852254433237063\n",
      "Train loss: 1.356455528812044\n",
      "\n",
      "Test set: Avg. loss: 0.0005856938660144806, AUC: 0.770606\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007252647280693055, AUC: 0.8370169999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010751946568489075, AUC: 0.818026\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006995381414890289, AUC: 0.2519855\n",
      "\n",
      "Train loss: 2.237226761070786\n",
      "Train loss: 2.370444839167747\n",
      "Train loss: 1.946292933764731\n",
      "Train loss: 2.0504455456308497\n",
      "Train loss: 2.285924324564114\n",
      "Train loss: 1.56150259333811\n",
      "Train loss: 1.8155106898326023\n",
      "\n",
      "Test set: Avg. loss: 0.0006007141172885895, AUC: 0.7845150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007254762947559357, AUC: 0.642412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005840370655059814, AUC: 0.892568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007031772136688232, AUC: 0.263741\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2023347259327104\n",
      "Train loss: 1.1260886385941962\n",
      "Train loss: 1.2624305676502787\n",
      "Train loss: 1.3076492407519347\n",
      "Train loss: 1.6729817743513995\n",
      "Train loss: 0.932061409115032\n",
      "Train loss: 1.1930139406471496\n",
      "\n",
      "Test set: Avg. loss: 0.0005784616768360138, AUC: 0.790336\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005655935108661652, AUC: 0.8682270000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000827675849199295, AUC: 0.8507750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00069707390666008, AUC: 0.5197765\n",
      "\n",
      "Train loss: 1.2094121252655223\n",
      "Train loss: 1.215760505123503\n",
      "Train loss: 1.1046511136042845\n",
      "Train loss: 1.806936825916266\n",
      "Train loss: 1.2945188477540472\n",
      "Train loss: 1.0583949100439716\n",
      "Train loss: 1.2277944441054278\n",
      "\n",
      "Test set: Avg. loss: 0.0006097620129585266, AUC: 0.774412\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007776130139827729, AUC: 0.834867\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009882590174674988, AUC: 0.8569760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000694716602563858, AUC: 0.480065\n",
      "\n",
      "Train loss: 1.8725317409084101\n",
      "Train loss: 2.1502137772596566\n",
      "Train loss: 1.6870755097668642\n",
      "Train loss: 1.6357368830662624\n",
      "Train loss: 1.2533696631717075\n",
      "Train loss: 1.35168056503223\n",
      "Train loss: 1.5414901125203273\n",
      "\n",
      "Test set: Avg. loss: 0.000649427592754364, AUC: 0.7784915000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006215007901191711, AUC: 0.846183\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006927695274353028, AUC: 0.8868935000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006856929957866669, AUC: 0.7430064999999999\n",
      "\n",
      "Train loss: 1.7669446631601662\n",
      "Train loss: 1.1983431251185714\n",
      "Train loss: 1.2303933558190705\n",
      "Train loss: 1.1651113549615169\n",
      "Train loss: 1.2903494948794128\n",
      "Train loss: 1.260611824548928\n",
      "Train loss: 1.0597109612385938\n",
      "\n",
      "Test set: Avg. loss: 0.0005798161327838898, AUC: 0.784816\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006663260459899902, AUC: 0.859489\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007123038172721863, AUC: 0.877735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007002768218517303, AUC: 0.29917950000000004\n",
      "\n",
      "Train loss: 2.2643725872039795\n",
      "Train loss: 1.7465672439830318\n",
      "Train loss: 1.8595942509402135\n",
      "Train loss: 1.69849788649067\n",
      "Train loss: 1.6699647789548158\n",
      "Train loss: 1.6494327555796144\n",
      "Train loss: 1.1151937884130296\n",
      "\n",
      "Test set: Avg. loss: 0.0005664527714252472, AUC: 0.7994279999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006068637371063233, AUC: 0.867908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007644516825675964, AUC: 0.867605\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006955388784408569, AUC: 0.43174399999999996\n",
      "\n",
      "Train loss: 3.1131190851235844\n",
      "Train loss: 2.9605272416096584\n",
      "Train loss: 2.6535338596173914\n",
      "Train loss: 2.6631418986684956\n",
      "Train loss: 1.5134806632995605\n",
      "Train loss: 1.8294462971626573\n",
      "Train loss: 2.5999999391804836\n",
      "\n",
      "Test set: Avg. loss: 0.0006070755124092102, AUC: 0.787339\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006761428117752075, AUC: 0.837387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008999312818050385, AUC: 0.8478159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007048081159591675, AUC: 0.2456025\n",
      "\n",
      "Train loss: 1.1607889521653485\n",
      "Train loss: 0.9156098263278888\n",
      "Train loss: 1.0303514178391475\n",
      "Train loss: 1.1994340469123452\n",
      "Train loss: 0.905778375400859\n",
      "Train loss: 1.0364113096978254\n",
      "Train loss: 0.9860802418107439\n",
      "\n",
      "Test set: Avg. loss: 0.0005870323479175568, AUC: 0.786627\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006674180328845977, AUC: 0.8605640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006862785816192626, AUC: 0.8835199999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007015574276447296, AUC: 0.4878665\n",
      "\n",
      "Train loss: 1.908454254174688\n",
      "Train loss: 1.6051180977730235\n",
      "Train loss: 2.1240639652416204\n",
      "Train loss: 1.8940567324875266\n",
      "Train loss: 1.5096366507991863\n",
      "Train loss: 1.6270241156505172\n",
      "Train loss: 1.2508507040655537\n",
      "\n",
      "Test set: Avg. loss: 0.000586001306772232, AUC: 0.773644\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006442296206951141, AUC: 0.8639159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008840581476688385, AUC: 0.854731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006965462565422058, AUC: 0.4099165\n",
      "\n",
      "Train loss: 1.4078618531014508\n",
      "Train loss: 1.0061944707943375\n",
      "Train loss: 1.7175687570480784\n",
      "Train loss: 0.9878252767453528\n",
      "Train loss: 1.1961874039309799\n",
      "Train loss: 1.176808558831549\n",
      "Train loss: 0.8958499936541174\n",
      "\n",
      "Test set: Avg. loss: 0.0005602919161319732, AUC: 0.8135689999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007259003520011902, AUC: 0.8733299999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010708312392234802, AUC: 0.8493509999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006917796134948731, AUC: 0.572626\n",
      "\n",
      "Train loss: 1.4843925643878377\n",
      "Train loss: 1.4706998619304341\n",
      "Train loss: 1.4346660588197648\n",
      "Train loss: 1.0114505856659761\n",
      "Train loss: 1.3573885438548532\n",
      "Train loss: 0.9401018277854677\n",
      "Train loss: 1.2780294558804506\n",
      "\n",
      "Test set: Avg. loss: 0.0005541979074478149, AUC: 0.8322359999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005823479294776916, AUC: 0.8760579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010248578190803527, AUC: 0.8324590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000706457108259201, AUC: 0.293338\n",
      "\n",
      "Train loss: 2.187117005609403\n",
      "Train loss: 1.7495554188254532\n",
      "Train loss: 1.8038792378583532\n",
      "Train loss: 1.6076770216036753\n",
      "Train loss: 1.7230843757368197\n",
      "Train loss: 1.7182611371301542\n",
      "Train loss: 1.9105631363619664\n",
      "\n",
      "Test set: Avg. loss: 0.0005487228631973266, AUC: 0.8238479999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011666412353515624, AUC: 0.724491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012003506422042847, AUC: 0.859466\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006960007846355438, AUC: 0.4713145\n",
      "\n",
      "Train loss: 0.5940645690176897\n",
      "Train loss: 0.7429805644758188\n",
      "Train loss: 0.5563166373094935\n",
      "Train loss: 0.45834486651572454\n",
      "Train loss: 0.7095175624653033\n",
      "Train loss: 0.5472447321673107\n",
      "Train loss: 0.38288218466339596\n",
      "\n",
      "Test set: Avg. loss: 0.0005755408704280853, AUC: 0.8181390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010223776400089264, AUC: 0.839647\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006376637518405914, AUC: 0.8413200000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006836646795272827, AUC: 0.7401239999999999\n",
      "\n",
      "Train loss: 0.7634054012359328\n",
      "Train loss: 0.8307750673051093\n",
      "Train loss: 0.98801563272051\n",
      "Train loss: 1.1928484728381892\n",
      "Train loss: 0.8857019892923391\n",
      "Train loss: 0.6685199650229922\n",
      "Train loss: 0.7200864113060532\n",
      "\n",
      "Test set: Avg. loss: 0.0005438500344753266, AUC: 0.818114\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000757246971130371, AUC: 0.8597279999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009142121374607086, AUC: 0.869603\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006938148140907288, AUC: 0.513664\n",
      "\n",
      "Train loss: 2.7329508779914518\n",
      "Train loss: 2.3173404969986837\n",
      "Train loss: 2.1407583519152014\n",
      "Train loss: 2.5490644429899323\n",
      "Train loss: 2.1265824342229562\n",
      "Train loss: 2.114899859686566\n",
      "Train loss: 2.059206382484193\n",
      "\n",
      "Test set: Avg. loss: 0.0005683489441871643, AUC: 0.8288869999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007981648743152619, AUC: 0.850436\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013745452761650086, AUC: 0.8253640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006944115459918976, AUC: 0.4860805\n",
      "\n",
      "Train loss: 2.25191767618155\n",
      "Train loss: 1.7917374828059203\n",
      "Train loss: 1.7485274638339972\n",
      "Train loss: 1.797163094304929\n",
      "Train loss: 1.7530826113785907\n",
      "Train loss: 1.4043480332489986\n",
      "Train loss: 1.547738418077967\n",
      "\n",
      "Test set: Avg. loss: 0.0005487594902515411, AUC: 0.8254940000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008763200938701629, AUC: 0.8483529999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010909561812877655, AUC: 0.8575109999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006897887289524079, AUC: 0.6485835\n",
      "\n",
      "Train loss: 2.0360326478435735\n",
      "Train loss: 2.010241811442527\n",
      "Train loss: 1.4924158970261836\n",
      "Train loss: 1.8178569359384524\n",
      "Train loss: 1.5814601201919993\n",
      "Train loss: 1.3880322541400885\n",
      "Train loss: 1.1700627325446742\n",
      "\n",
      "Test set: Avg. loss: 0.0005867069959640503, AUC: 0.832389\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011520668268203734, AUC: 0.8385640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012785077691078186, AUC: 0.852769\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007080322802066803, AUC: 0.24347450000000004\n",
      "\n",
      "Train loss: 0.5796154517277031\n",
      "Train loss: 0.5583032999828363\n",
      "Train loss: 0.5621575823255406\n",
      "Train loss: 0.6991059210649722\n",
      "Train loss: 0.5377250685813321\n",
      "Train loss: 0.7783492389757922\n",
      "Train loss: 0.5535165891525852\n",
      "\n",
      "Test set: Avg. loss: 0.0005291039943695068, AUC: 0.841594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007950236201286316, AUC: 0.871008\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015735960006713868, AUC: 0.6460125\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006973163485527039, AUC: 0.3920135\n",
      "\n",
      "Train loss: 2.791748259857202\n",
      "Train loss: 2.302309560168321\n",
      "Train loss: 1.506906279333078\n",
      "Train loss: 1.1021962894755564\n",
      "Train loss: 2.1394176490747245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.2612491887845811\n",
      "Train loss: 1.1313921216946499\n",
      "\n",
      "Test set: Avg. loss: 0.0005779439210891724, AUC: 0.8200909999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007442227005958557, AUC: 0.8520730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009915706515312194, AUC: 0.866611\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006961906254291534, AUC: 0.356847\n",
      "\n",
      "Train loss: 1.6302833951962221\n",
      "Train loss: 1.1831953927969476\n",
      "Train loss: 1.3946104983615268\n",
      "Train loss: 0.655754076827104\n",
      "Train loss: 0.6458332158957317\n",
      "Train loss: 0.5085545391034169\n",
      "Train loss: 0.5506968760186699\n",
      "\n",
      "Test set: Avg. loss: 0.0006036537587642669, AUC: 0.8844140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001022331804037094, AUC: 0.874194\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002027942895889282, AUC: 0.8447259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006906534433364868, AUC: 0.594153\n",
      "\n",
      "Train loss: 1.3279404207399697\n",
      "Train loss: 1.2319500503266694\n",
      "Train loss: 0.741771079172754\n",
      "Train loss: 0.9240231597499483\n",
      "Train loss: 0.9467883056895748\n",
      "Train loss: 0.8489766037388212\n",
      "Train loss: 0.8699636930113386\n",
      "\n",
      "Test set: Avg. loss: 0.0007414828836917877, AUC: 0.8404829999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020879905223846434, AUC: 0.8331\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002396840453147888, AUC: 0.8437625\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006928616762161255, AUC: 0.6468499999999999\n",
      "\n",
      "Train loss: 1.78923861426153\n",
      "Train loss: 0.9392263805790312\n",
      "Train loss: 1.1556416267802\n",
      "Train loss: 0.884982205879916\n",
      "Train loss: 0.8122148802325984\n",
      "Train loss: 0.3455366488474949\n",
      "Train loss: 0.37879747835693844\n",
      "\n",
      "Test set: Avg. loss: 0.0006871826946735383, AUC: 0.8843909999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012586455345153808, AUC: 0.8426269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019782032370567323, AUC: 0.8711929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007054244577884674, AUC: 0.3777935\n",
      "\n",
      "Train loss: 1.3173786481474614\n",
      "Train loss: 1.1111591321647547\n",
      "Train loss: 0.8924773043128336\n",
      "Train loss: 0.6198340722709704\n",
      "Train loss: 0.869989304026221\n",
      "Train loss: 0.4205582043167892\n",
      "Train loss: 0.3459680125971509\n",
      "\n",
      "Test set: Avg. loss: 0.0005359562337398529, AUC: 0.8288425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001699045777320862, AUC: 0.805252\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001953969180583954, AUC: 0.729222\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006922256052494049, AUC: 0.5383795\n",
      "\n",
      "Train loss: 1.6573405064594973\n",
      "Train loss: 1.281090005947526\n",
      "Train loss: 1.3745880590122976\n",
      "Train loss: 0.9545093846928542\n",
      "Train loss: 0.7423891558009348\n",
      "Train loss: 0.6719815176763352\n",
      "Train loss: 0.404710110585401\n",
      "\n",
      "Test set: Avg. loss: 0.000668381690979004, AUC: 0.8237229999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014707709550857543, AUC: 0.8647680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002450863480567932, AUC: 0.7930949999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006985143721103668, AUC: 0.296268\n",
      "\n",
      "Train loss: 1.0509823780910226\n",
      "Train loss: 0.8213566666955401\n",
      "Train loss: 0.8391928809463598\n",
      "Train loss: 0.606975953290417\n",
      "Train loss: 0.7590702992336006\n",
      "Train loss: 0.39098546687205127\n",
      "Train loss: 0.43912579223608517\n",
      "\n",
      "Test set: Avg. loss: 0.0006864502727985382, AUC: 0.859043\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008696517050266266, AUC: 0.7427465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002363202095031738, AUC: 0.842159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006962572634220123, AUC: 0.4520185\n",
      "\n",
      "Train loss: 1.6196966736939302\n",
      "Train loss: 0.9409983484608353\n",
      "Train loss: 1.3153672560005432\n",
      "Train loss: 1.12715274285359\n",
      "Train loss: 0.9786882408105644\n",
      "Train loss: 0.6121147081350825\n",
      "Train loss: 0.8889125251466301\n",
      "\n",
      "Test set: Avg. loss: 0.0010649966597557068, AUC: 0.8016599999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016026557683944702, AUC: 0.88021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0023014358282089234, AUC: 0.8509375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006933611333370209, AUC: 0.5018925\n",
      "\n",
      "Train loss: 0.6691017792483044\n",
      "Train loss: 0.7474540521384804\n",
      "Train loss: 0.7382226096596688\n",
      "Train loss: 0.6048336575745018\n",
      "Train loss: 0.5350011325186226\n",
      "Train loss: 0.34166531388167365\n",
      "Train loss: 0.4478928416397921\n",
      "\n",
      "Test set: Avg. loss: 0.0008539587557315826, AUC: 0.891673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015055554509162902, AUC: 0.8422160000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001958116710186005, AUC: 0.847298\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006890646517276764, AUC: 0.634431\n",
      "\n",
      "Train loss: 2.209489019053757\n",
      "Train loss: 1.4154836694905713\n",
      "Train loss: 1.0294480251658493\n",
      "Train loss: 0.6568275378767852\n",
      "Train loss: 0.689401167972832\n",
      "Train loss: 0.8061980863285673\n",
      "Train loss: 0.7038110346551154\n",
      "\n",
      "Test set: Avg. loss: 0.0006595695912837982, AUC: 0.877006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012591845393180848, AUC: 0.8771930000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020265308618545533, AUC: 0.8502069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006885253489017487, AUC: 0.6347674999999999\n",
      "\n",
      "Train loss: 1.8656461087002116\n",
      "Train loss: 1.6614939092071193\n",
      "Train loss: 1.8042969980816932\n",
      "Train loss: 1.0011003154098608\n",
      "Train loss: 0.9157375161814841\n",
      "Train loss: 0.686819005923666\n",
      "Train loss: 0.8154869398493676\n",
      "\n",
      "Test set: Avg. loss: 0.00056703981757164, AUC: 0.877735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001410290539264679, AUC: 0.8875850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002173173189163208, AUC: 0.862714\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006982824206352234, AUC: 0.289144\n",
      "\n",
      "Train loss: 2.06194356292676\n",
      "Train loss: 1.7978967978696154\n",
      "Train loss: 1.2610262214757835\n",
      "Train loss: 0.8824931068025577\n",
      "Train loss: 0.7289010088914519\n",
      "Train loss: 0.9268005015743765\n",
      "Train loss: 0.805660572780925\n",
      "\n",
      "Test set: Avg. loss: 0.000560793161392212, AUC: 0.807079\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011872678995132446, AUC: 0.6604994999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001035401850938797, AUC: 0.8357199999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000685053288936615, AUC: 0.6776139999999999\n",
      "\n",
      "Train loss: 0.814997014346396\n",
      "Train loss: 0.7473016620441607\n",
      "Train loss: 0.7269381212580736\n",
      "Train loss: 1.0181603530409988\n",
      "Train loss: 0.4592938776228838\n",
      "Train loss: 0.40015815587560083\n",
      "Train loss: 0.6243326846201709\n",
      "\n",
      "Test set: Avg. loss: 0.0005558441281318664, AUC: 0.83245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007354770004749298, AUC: 0.863535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001000113755464554, AUC: 0.8627\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006936974227428436, AUC: 0.5445135000000001\n",
      "\n",
      "Train loss: 2.191950939643155\n",
      "Train loss: 2.0115896429225897\n",
      "Train loss: 1.3578787001834554\n",
      "Train loss: 0.8644259701109236\n",
      "Train loss: 1.0628144539845217\n",
      "Train loss: 0.9245298204907946\n",
      "Train loss: 0.811612954944562\n",
      "\n",
      "Test set: Avg. loss: 0.0005369468629360199, AUC: 0.8408559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001122730791568756, AUC: 0.830062\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000643302708864212, AUC: 0.730758\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007071824669837952, AUC: 0.31716099999999997\n",
      "\n",
      "Train loss: 2.0404329577069373\n",
      "Train loss: 1.751568711487351\n",
      "Train loss: 1.4856392418503002\n",
      "Train loss: 1.223580913558887\n",
      "Train loss: 0.6177962490707446\n",
      "Train loss: 0.6464955563757829\n",
      "Train loss: 0.5280925604947813\n",
      "\n",
      "Test set: Avg. loss: 0.0005691903829574585, AUC: 0.8248979999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009515962600708008, AUC: 0.8475480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008355998694896698, AUC: 0.8772249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000692710131406784, AUC: 0.54984\n",
      "\n",
      "Train loss: 1.700349251555789\n",
      "Train loss: 1.4860063092723774\n",
      "Train loss: 0.705057531025759\n",
      "Train loss: 0.8467261719096238\n",
      "Train loss: 0.517881221072689\n",
      "Train loss: 0.7075597602091018\n",
      "Train loss: 0.1673807524571753\n",
      "\n",
      "Test set: Avg. loss: 0.0005903262794017791, AUC: 0.85848\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008274651169776916, AUC: 0.87113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008652732372283936, AUC: 0.888093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006938183903694153, AUC: 0.48964949999999996\n",
      "\n",
      "Train loss: 2.9466677205577776\n",
      "Train loss: 2.1237854874058133\n",
      "Train loss: 1.7789595643426204\n",
      "Train loss: 1.302825991135494\n",
      "Train loss: 0.8595462669232848\n",
      "Train loss: 0.9368057953324288\n",
      "Train loss: 0.8344736175172648\n",
      "\n",
      "Test set: Avg. loss: 0.0005606429874897003, AUC: 0.8235150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007379675805568695, AUC: 0.8703829999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011381646990776062, AUC: 0.853367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000692952960729599, AUC: 0.512215\n",
      "\n",
      "Train loss: 1.3447510535549965\n",
      "Train loss: 1.5659122713811837\n",
      "Train loss: 0.7784969556103846\n",
      "Train loss: 1.0352774520588528\n",
      "Train loss: 0.5811889422167639\n",
      "Train loss: 0.9382684113113744\n",
      "Train loss: 0.35392030599010976\n",
      "\n",
      "Test set: Avg. loss: 0.0005473651289939881, AUC: 0.8225480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008825469315052033, AUC: 0.8500289999999999\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0009700717628002166, AUC: 0.8710479999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007009858787059784, AUC: 0.274546\n",
      "\n",
      "Train loss: 1.0191231256078004\n",
      "Train loss: 0.8665515875360769\n",
      "Train loss: 0.5478816286773439\n",
      "Train loss: 0.5934320802141906\n",
      "Train loss: 0.4585166429258456\n",
      "Train loss: 0.36518256527603055\n",
      "Train loss: 0.2766122594001187\n",
      "\n",
      "Test set: Avg. loss: 0.0005422953069210053, AUC: 0.8300485\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009197070300579071, AUC: 0.862573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007927222549915314, AUC: 0.891192\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006937234699726105, AUC: 0.505826\n",
      "\n",
      "Train loss: 1.78541615282654\n",
      "Train loss: 1.1110326120048573\n",
      "Train loss: 1.062967714610373\n",
      "Train loss: 0.3780218108444457\n",
      "Train loss: 0.6052714833028757\n",
      "Train loss: 0.3628141678822268\n",
      "Train loss: 0.4713394584929108\n",
      "\n",
      "Test set: Avg. loss: 0.000610990047454834, AUC: 0.8591884999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008457472026348114, AUC: 0.8621699999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012760106921195983, AUC: 0.8272209999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006888211369514465, AUC: 0.7117939999999999\n",
      "\n",
      "Train loss: 2.1524108131979682\n",
      "Train loss: 1.565488024881691\n",
      "Train loss: 0.9556463721451486\n",
      "Train loss: 1.1934015154838562\n",
      "Train loss: 0.8894191824706497\n",
      "Train loss: 0.7956692527054222\n",
      "Train loss: 0.534850889330457\n",
      "\n",
      "Test set: Avg. loss: 0.0005873701870441437, AUC: 0.827129\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010476004481315612, AUC: 0.8193855000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013036265969276427, AUC: 0.8209709999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000694722294807434, AUC: 0.40770600000000007\n",
      "\n",
      "Train loss: 0.7960313759791623\n",
      "Train loss: 0.9983759435119143\n",
      "Train loss: 1.1034056100116414\n",
      "Train loss: 0.9029658482332897\n",
      "Train loss: 0.7090614229250866\n",
      "Train loss: 0.7798255104927501\n",
      "Train loss: 1.0286505009718\n",
      "\n",
      "Test set: Avg. loss: 0.0006182847619056702, AUC: 0.7983094999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005962693691253662, AUC: 0.8486179999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008046212792396546, AUC: 0.879212\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007035067975521088, AUC: 0.3294395\n",
      "\n",
      "Train loss: 2.1331852647908933\n",
      "Train loss: 2.485901011023552\n",
      "Train loss: 2.068312706461378\n",
      "Train loss: 1.6931261029213098\n",
      "Train loss: 1.5992624452159663\n",
      "Train loss: 1.4256088714690724\n",
      "Train loss: 1.4400900325198083\n",
      "\n",
      "Test set: Avg. loss: 0.0005714722275733948, AUC: 0.8017049999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005746656954288482, AUC: 0.851167\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00093332239985466, AUC: 0.845108\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006914713978767395, AUC: 0.5854445\n",
      "\n",
      "Train loss: 2.259106214638728\n",
      "Train loss: 2.396307418680495\n",
      "Train loss: 1.890025010534153\n",
      "Train loss: 1.6914104082781798\n",
      "Train loss: 1.816535103093287\n",
      "Train loss: 1.8390479201723815\n",
      "Train loss: 1.5347183187296436\n",
      "\n",
      "Test set: Avg. loss: 0.0005907627046108245, AUC: 0.7681135000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006269663274288177, AUC: 0.8551489999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007813455462455749, AUC: 0.857493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006914409101009369, AUC: 0.574384\n",
      "\n",
      "Train loss: 3.5315048295980804\n",
      "Train loss: 2.939624161856949\n",
      "Train loss: 2.740274903121268\n",
      "Train loss: 2.463548212294366\n",
      "Train loss: 2.473973011514943\n",
      "Train loss: 1.7253758801016839\n",
      "Train loss: 1.864735111689112\n",
      "\n",
      "Test set: Avg. loss: 0.0005781789720058441, AUC: 0.789895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007055032551288604, AUC: 0.849969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007596215903759002, AUC: 0.8581725\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006830983757972717, AUC: 0.679951\n",
      "\n",
      "Train loss: 3.8425584420277055\n",
      "Train loss: 3.599155702788359\n",
      "Train loss: 3.120476687410075\n",
      "Train loss: 3.8126375500563605\n",
      "Train loss: 3.26338308062523\n",
      "Train loss: 3.380072189364464\n",
      "Train loss: 2.8174194442998073\n",
      "\n",
      "Test set: Avg. loss: 0.0005767131745815277, AUC: 0.7875230000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006306368708610535, AUC: 0.836691\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007802184224128723, AUC: 0.849869\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006942238807678223, AUC: 0.47882399999999997\n",
      "\n",
      "Train loss: 2.8961449740039313\n",
      "Train loss: 2.3131131696852907\n",
      "Train loss: 1.5589302239144684\n",
      "Train loss: 1.4870115127533106\n",
      "Train loss: 1.8942063409052077\n",
      "Train loss: 1.675782716957627\n",
      "Train loss: 1.3493538620365653\n",
      "\n",
      "Test set: Avg. loss: 0.0005801919400691986, AUC: 0.7885470000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006489315330982208, AUC: 0.8562069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000686212807893753, AUC: 0.8568910000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000702318012714386, AUC: 0.47689200000000004\n",
      "\n",
      "Train loss: 3.0888956246102692\n",
      "Train loss: 2.1883418973843765\n",
      "Train loss: 2.761501152424296\n",
      "Train loss: 1.9197437432920856\n",
      "Train loss: 2.3957514026362423\n",
      "Train loss: 2.476614553077965\n",
      "Train loss: 1.9464446587167727\n",
      "\n",
      "Test set: Avg. loss: 0.0005919966399669647, AUC: 0.786168\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007108605206012726, AUC: 0.835431\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008454965353012085, AUC: 0.855029\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006921489536762238, AUC: 0.5849125\n",
      "\n",
      "Train loss: 1.9206807146406477\n",
      "Train loss: 1.9859962326705836\n",
      "Train loss: 1.8692850470542908\n",
      "Train loss: 1.9047155547293888\n",
      "Train loss: 1.1671133170461958\n",
      "Train loss: 1.2669680429871675\n",
      "Train loss: 1.3530608370045947\n",
      "\n",
      "Test set: Avg. loss: 0.0005869621336460114, AUC: 0.7798599999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005831846594810486, AUC: 0.846829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007644911706447601, AUC: 0.859388\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006940556168556213, AUC: 0.6705585000000001\n",
      "\n",
      "Train loss: 1.4609876802772472\n",
      "Train loss: 1.167148787884196\n",
      "Train loss: 1.2125620967263628\n",
      "Train loss: 1.2234868984313527\n",
      "Train loss: 1.1763024576909982\n",
      "Train loss: 1.000514233567912\n",
      "Train loss: 1.3175612372957217\n",
      "\n",
      "Test set: Avg. loss: 0.0006125179529190063, AUC: 0.799903\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006348290145397187, AUC: 0.8782379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006080363392829895, AUC: 0.8996190000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006875421702861786, AUC: 0.6909959999999999\n",
      "\n",
      "Train loss: 1.2969169259830644\n",
      "Train loss: 1.2333932872031146\n",
      "Train loss: 1.0415245469208736\n",
      "Train loss: 1.0296513047187952\n",
      "Train loss: 1.030990808632723\n",
      "Train loss: 0.924019289244512\n",
      "Train loss: 1.2392508228113697\n",
      "\n",
      "Test set: Avg. loss: 0.0005743894875049591, AUC: 0.7870490000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006739238202571869, AUC: 0.8518830000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000825771450996399, AUC: 0.8549049999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006968843638896942, AUC: 0.4236895\n",
      "\n",
      "Train loss: 1.31517015976511\n",
      "Train loss: 1.2638685938658987\n",
      "Train loss: 1.2530524039724071\n",
      "Train loss: 0.9679147426489811\n",
      "Train loss: 1.3095108403521738\n",
      "Train loss: 1.3981786617048226\n",
      "Train loss: 1.1922624760372624\n",
      "\n",
      "Test set: Avg. loss: 0.0005437677502632141, AUC: 0.823285\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000610975980758667, AUC: 0.8825569999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009636357724666596, AUC: 0.8721639999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006896005570888519, AUC: 0.711947\n",
      "\n",
      "Train loss: 0.9401467651318592\n",
      "Train loss: 1.1714389012877349\n",
      "Train loss: 0.6422754089543774\n",
      "Train loss: 1.1516999154333856\n",
      "Train loss: 0.9084152974140872\n",
      "Train loss: 0.7241029648264502\n",
      "Train loss: 0.5629237878854108\n",
      "\n",
      "Test set: Avg. loss: 0.0005527506768703461, AUC: 0.8383090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007655405104160308, AUC: 0.8776750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006529793739318847, AUC: 0.8764664999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006917674541473389, AUC: 0.6441645\n",
      "\n",
      "Train loss: 1.3845846975684926\n",
      "Train loss: 1.8438648456221174\n",
      "Train loss: 1.6540579514898313\n",
      "Train loss: 1.6892845463600887\n",
      "Train loss: 1.4202518197381573\n",
      "Train loss: 1.4520534861619305\n",
      "Train loss: 1.6947100572525315\n",
      "\n",
      "Test set: Avg. loss: 0.0005471716821193695, AUC: 0.8448060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006678911745548248, AUC: 0.7377870000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010596026182174683, AUC: 0.861699\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006997432112693787, AUC: 0.4992215\n",
      "\n",
      "Train loss: 1.9212441854416185\n",
      "Train loss: 1.791586533093908\n",
      "Train loss: 1.5869469278177637\n",
      "Train loss: 1.5589140414432356\n",
      "Train loss: 1.137625529128275\n",
      "Train loss: 1.924669845468679\n",
      "Train loss: 0.749810179707351\n",
      "\n",
      "Test set: Avg. loss: 0.0005840785801410675, AUC: 0.811204\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001008741557598114, AUC: 0.8383579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008155434727668763, AUC: 0.8744120000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006977493464946746, AUC: 0.33962349999999997\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.73941829250117\n",
      "Train loss: 3.0514345605661917\n",
      "Train loss: 3.104643801974643\n",
      "Train loss: 2.612534505546473\n",
      "Train loss: 3.0523950939725157\n",
      "Train loss: 2.736357009714576\n",
      "Train loss: 2.487650365206846\n",
      "\n",
      "Test set: Avg. loss: 0.0005795770883560181, AUC: 0.811379\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009680385887622833, AUC: 0.834955\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014414542317390442, AUC: 0.812766\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007007932364940644, AUC: 0.3357205\n",
      "\n",
      "Train loss: 2.0767022090353024\n",
      "Train loss: 2.7588721627642396\n",
      "Train loss: 2.3932931764869934\n",
      "Train loss: 1.988753900406467\n",
      "Train loss: 1.9661894076189417\n",
      "Train loss: 1.6306139564817879\n",
      "Train loss: 1.5500993246485473\n",
      "\n",
      "Test set: Avg. loss: 0.0005616866648197174, AUC: 0.8354760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007120003402233124, AUC: 0.86705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011443256735801696, AUC: 0.848986\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006950245201587677, AUC: 0.411188\n",
      "\n",
      "Train loss: 0.8769399899585991\n",
      "Train loss: 1.06430680243073\n",
      "Train loss: 0.918808770407537\n",
      "Train loss: 0.7530246168185192\n",
      "Train loss: 0.8258661308865638\n",
      "Train loss: 0.5527872910165483\n",
      "Train loss: 0.6075567329765126\n",
      "\n",
      "Test set: Avg. loss: 0.0005491219460964202, AUC: 0.836193\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005059432089328766, AUC: 0.844494\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009892673194408417, AUC: 0.871371\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006959825754165649, AUC: 0.5022235\n",
      "\n",
      "Train loss: 2.6494461442254913\n",
      "Train loss: 1.7696866882834466\n",
      "Train loss: 1.3492375092141946\n",
      "Train loss: 1.7484730425154327\n",
      "Train loss: 1.4763848671487942\n",
      "Train loss: 1.2793041919447055\n",
      "Train loss: 1.5354833796525458\n",
      "\n",
      "Test set: Avg. loss: 0.0005648266971111297, AUC: 0.8296570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009923055469989778, AUC: 0.854608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000786138653755188, AUC: 0.8866660000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006978760957717895, AUC: 0.385427\n",
      "\n",
      "Train loss: 1.4440960937244878\n",
      "Train loss: 1.2017468111530232\n",
      "Train loss: 1.1101228207539602\n",
      "Train loss: 0.7894483011239654\n",
      "Train loss: 1.009758954594849\n",
      "Train loss: 0.9738095808940329\n",
      "Train loss: 1.1869930192163796\n",
      "\n",
      "Test set: Avg. loss: 0.0005799872577190399, AUC: 0.828694\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006988342106342316, AUC: 0.883639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000912466436624527, AUC: 0.8836579999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006947050988674164, AUC: 0.4902065\n",
      "\n",
      "Train loss: 3.3168110657649437\n",
      "Train loss: 3.270961747807302\n",
      "Train loss: 2.687219317551631\n",
      "Train loss: 2.3028279174664976\n",
      "Train loss: 2.3162201620211267\n",
      "Train loss: 2.976252863741225\n",
      "Train loss: 2.0545171575181804\n",
      "\n",
      "Test set: Avg. loss: 0.0005629383325576783, AUC: 0.824377\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010071962475776673, AUC: 0.8247\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009438264966011048, AUC: 0.869693\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006935038268566132, AUC: 0.48691850000000003\n",
      "\n",
      "Train loss: 1.0355363013638053\n",
      "Train loss: 0.7906266318005362\n",
      "Train loss: 0.8340024374852515\n",
      "Train loss: 0.6697178703204841\n",
      "Train loss: 0.5793825167759209\n",
      "Train loss: 0.3153650961863767\n",
      "Train loss: 0.2980445460149437\n",
      "\n",
      "Test set: Avg. loss: 0.0006255601346492767, AUC: 0.8395660000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000972646564245224, AUC: 0.8613489999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016382681727409364, AUC: 0.8700494999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000697717696428299, AUC: 0.397584\n",
      "\n",
      "Train loss: 2.122518780504822\n",
      "Train loss: 1.3025779625412766\n",
      "Train loss: 0.8739714140345336\n",
      "Train loss: 0.5010068758278136\n",
      "Train loss: 0.8078536805073926\n",
      "Train loss: 0.5291196658353138\n",
      "Train loss: 0.6185452121837883\n",
      "\n",
      "Test set: Avg. loss: 0.0007597030103206634, AUC: 0.8673609999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007095710039138794, AUC: 0.8771799999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015857835412025451, AUC: 0.870952\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000694392740726471, AUC: 0.5617129999999999\n",
      "\n",
      "Train loss: 0.8434646953443053\n",
      "Train loss: 1.1943337799637181\n",
      "Train loss: 0.7621696929263461\n",
      "Train loss: 0.5459835278760096\n",
      "Train loss: 0.5428079176860251\n",
      "Train loss: 0.5287577342835201\n",
      "Train loss: 0.3909614462002068\n",
      "\n",
      "Test set: Avg. loss: 0.0006358371376991272, AUC: 0.8924289999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011346283555030822, AUC: 0.880171\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001961418092250824, AUC: 0.561781\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006900477409362793, AUC: 0.6276174999999999\n",
      "\n",
      "Train loss: 1.3244658492173358\n",
      "Train loss: 1.4524547510845647\n",
      "Train loss: 0.7488276719287702\n",
      "Train loss: 0.9933133132898124\n",
      "Train loss: 0.6002143587276434\n",
      "Train loss: 0.3301696712803689\n",
      "Train loss: 0.19093394317444723\n",
      "\n",
      "Test set: Avg. loss: 0.0005544925332069397, AUC: 0.794265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001065571665763855, AUC: 0.885986\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014632765650749206, AUC: 0.882574\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000689701110124588, AUC: 0.6288199999999999\n",
      "\n",
      "Train loss: 2.5217519189901414\n",
      "Train loss: 1.436405793876405\n",
      "Train loss: 1.130695737091599\n",
      "Train loss: 0.6512467538475231\n",
      "Train loss: 0.5408507046426178\n",
      "Train loss: 0.6130503753947604\n",
      "Train loss: 0.3968999735109366\n",
      "\n",
      "Test set: Avg. loss: 0.0012304891347885132, AUC: 0.643656\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00160891592502594, AUC: 0.8128120000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019590254426002504, AUC: 0.841639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006931320130825043, AUC: 0.5277654999999999\n",
      "\n",
      "Train loss: 1.143061370606635\n",
      "Train loss: 1.2598705641023673\n",
      "Train loss: 0.7654081161614437\n",
      "Train loss: 1.044363485779732\n",
      "Train loss: 0.3597279475752715\n",
      "Train loss: 0.5793422183413415\n",
      "Train loss: 0.405704205962503\n",
      "\n",
      "Test set: Avg. loss: 0.0006529631614685059, AUC: 0.8839340000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010634871125221252, AUC: 0.883689\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010134038031101226, AUC: 0.886896\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006916421949863434, AUC: 0.5829845\n",
      "\n",
      "Train loss: 2.2191966954310227\n",
      "Train loss: 1.9962425816590619\n",
      "Train loss: 1.1565126036382785\n",
      "Train loss: 1.1856594381818346\n",
      "Train loss: 0.8443597908232622\n",
      "Train loss: 0.6324422329094759\n",
      "Train loss: 0.42677182376764383\n",
      "\n",
      "Test set: Avg. loss: 0.00048386648297309875, AUC: 0.871565\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009634788930416107, AUC: 0.877014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011245848536491393, AUC: 0.8783599999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00069866082072258, AUC: 0.3503775\n",
      "\n",
      "Train loss: 1.246828455454225\n",
      "Train loss: 1.392865396229325\n",
      "Train loss: 0.8969031105375593\n",
      "Train loss: 0.8762473619667588\n",
      "Train loss: 0.5711101134111927\n",
      "Train loss: 0.7954607002294747\n",
      "Train loss: 0.47130529591991643\n",
      "\n",
      "Test set: Avg. loss: 0.0005898977518081665, AUC: 0.8374539999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010013698041439055, AUC: 0.850913\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00210909903049469, AUC: 0.8312780000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006965936422348022, AUC: 0.470337\n",
      "\n",
      "Train loss: 0.8943633201775277\n",
      "Train loss: 1.0868087179341894\n",
      "Train loss: 0.939083539376593\n",
      "Train loss: 0.35449562217019925\n",
      "Train loss: 0.5633249833325672\n",
      "Train loss: 0.5125156208208412\n",
      "Train loss: 0.4626742931687908\n",
      "\n",
      "Test set: Avg. loss: 0.000779478132724762, AUC: 0.809216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011249300241470337, AUC: 0.883112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001801038384437561, AUC: 0.878852\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006942656636238098, AUC: 0.5234075\n",
      "\n",
      "Train loss: 2.1839576796361597\n",
      "Train loss: 1.1000779552064883\n",
      "Train loss: 0.9684593988831636\n",
      "Train loss: 0.8727992146637789\n",
      "Train loss: 0.457021970657786\n",
      "Train loss: 0.3693458046882775\n",
      "Train loss: 0.3603800675671571\n",
      "\n",
      "Test set: Avg. loss: 0.0006466010510921478, AUC: 0.8678509999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010035872757434845, AUC: 0.8683960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001744243323802948, AUC: 0.859271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# triplet loss first few epochs + capped smote (cosine distance)\n",
    "\n",
    "# 2 class triplet loss with capped SMOTE \n",
    "\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [(5e-6, 1e-2), (1e-6, 5e-3), (1e-6, 1e-2), (5e-6, 5e-2)]\n",
    "\n",
    "cap_aucs = []\n",
    "loss_fn_args = {}\n",
    "loss_caps = [0.75, 1, 5]\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "loss_fn_args['distance'] = 'cosine'\n",
    "start_epoch = 5\n",
    "\n",
    "for cap in loss_caps:\n",
    "    learning_rate_aucs = []\n",
    "    for learning_rate in learning_rates:\n",
    "        aucs = []\n",
    "        for i in range(10): \n",
    "            best_embed_network = None \n",
    "            best_loss = 100000000\n",
    "            model_aucs = []\n",
    "            embed_network = models.ConvNetOnlyEmbeddings(2)\n",
    "            linear_probe = models.ConvNetLinearProbe(2)\n",
    "            complete_network = models.CompleteConvNet(embed_network, linear_probe)\n",
    "            embed_optimizer = optim.SGD(embed_network.parameters(), lr=learning_rate[0], momentum=momentum)\n",
    "            linear_optimizer = optim.SGD(complete_network.parameters(), lr=learning_rate[1], momentum=momentum)\n",
    "            _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True) \n",
    "            model_aucs.append(auc)\n",
    "            for epoch in range(start_epoch):\n",
    "                _, train_losses = train.train_triplet_loss_smote(epoch, train_loader_tripletloss_smote, embed_network, embed_optimizer, verbose=False)\n",
    "                print(\"Train loss: Avg. loss: \" + str(np.mean(np.array(train_losses)) / len(train_loader.dataset)))\n",
    "                test_losses = metric_utils.triplet_loss(test_loader_tripletloss, embed_network)\n",
    "                if (test_losses[0] < best_loss and test_losses != 0):\n",
    "                    best_embed_network = copy.deepcopy(embed_network)\n",
    "                    best_loss = test_losses[0]\n",
    "            for epoch in range(start_epoch, n_epochs+1):\n",
    "                complete_network = models.CompleteConvNet(best_embed_network, linear_probe)\n",
    "                loss_fn_args['loss_cap'] = cap\n",
    "                loss_fn_args['avg_tensors'] = []\n",
    "                for k in range(2):\n",
    "                    avg_tensor = best_embed_network(avg_tensors_list[k])\n",
    "                    loss_fn_args['avg_tensors'].append(avg_tensor)\n",
    "                _, _ = train.train_sigmoid_with_embeddings(epoch, train_loader_smote, complete_network, linear_optimizer, verbose=False, loss_fn=loss_fns.CappedBCELossAvgDistance, loss_fn_args=loss_fn_args)\n",
    "                if (epoch + 1) % 10 == 0: \n",
    "                    _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                    model_aucs.append(auc) \n",
    "            aucs.append(model_aucs)\n",
    "        learning_rate_aucs.append(aucs)\n",
    "\n",
    "\n",
    "    learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "    auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "    auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "    cap_aucs.append([auc_mean, auc_variance])\n",
    "\n",
    "\n",
    "\n",
    "for c in range(len(cap_aucs)):\n",
    "    auc_mean = cap_aucs[c][0]\n",
    "    auc_variance = cap_aucs[c][1]\n",
    "    cap = loss_caps[c]\n",
    "    for i in range(len(learning_rates)): \n",
    "        row = [\"cosine_distance_capped_smote_with_smote_triplet_loss\", 2, nums, ratio, learning_rates[i],\n",
    "                auc_mean[i][0], auc_variance[i][0], \n",
    "                auc_mean[i][1], auc_variance[i][1],\n",
    "                auc_mean[i][2], auc_variance[i][2],\n",
    "                auc_mean[i][3], auc_variance[i][3], cap, norm, \"start_epoch=5\"]\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72051f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdcfc07b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.002039885640144348, AUC: 0.66023\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006628685593605041, AUC: 0.7356530000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006643344759941102, AUC: 0.773584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006539630889892578, AUC: 0.8037645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0047306792736053465, AUC: 0.6329575000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005529289841651917, AUC: 0.878345\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010869187712669373, AUC: 0.850248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008945511877536773, AUC: 0.8861870000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001632814586162567, AUC: 0.6211545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006615898311138153, AUC: 0.7973415000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006592643857002258, AUC: 0.8105370000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006474920809268951, AUC: 0.8341635000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011176564693450928, AUC: 0.5269135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006419839262962341, AUC: 0.8088095\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006355904936790466, AUC: 0.8086760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006805188357830047, AUC: 0.7266355000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00370810067653656, AUC: 0.4878315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006141901314258575, AUC: 0.810471\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006242124736309052, AUC: 0.8531869999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006020380556583404, AUC: 0.8618395000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0044698967933654785, AUC: 0.322459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006004904210567475, AUC: 0.776683\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006332120597362518, AUC: 0.869504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008490591049194336, AUC: 0.8612399999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002206212282180786, AUC: 0.348227\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005468548238277435, AUC: 0.8708959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004669896811246872, AUC: 0.8883219999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007768318057060242, AUC: 0.8741709999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000868158906698227, AUC: 0.614243\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006416294872760772, AUC: 0.8485069999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004904540330171585, AUC: 0.874335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004663666188716888, AUC: 0.875738\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.011904088020324707, AUC: 0.476242\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006860587596893311, AUC: 0.606916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000667123556137085, AUC: 0.7591800000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000659710943698883, AUC: 0.787448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002358026742935181, AUC: 0.3152315\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009614932537078858, AUC: 0.7943960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005179421901702881, AUC: 0.8717710000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006284619867801667, AUC: 0.867039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00261321496963501, AUC: 0.6088969999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005840716361999511, AUC: 0.84785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005194091796875, AUC: 0.878762\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007422075271606445, AUC: 0.8684885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008334369361400604, AUC: 0.542468\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006457299590110778, AUC: 0.7969100000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000652441531419754, AUC: 0.8005705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006225226521492004, AUC: 0.851298\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002156104922294617, AUC: 0.377825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006941834390163422, AUC: 0.5\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006806309223175049, AUC: 0.6543275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006574298143386841, AUC: 0.739428\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001286734402179718, AUC: 0.580974\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006333440840244293, AUC: 0.8179099999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006010175943374634, AUC: 0.8696090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006108177900314331, AUC: 0.86836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001448044776916504, AUC: 0.525961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006200965344905854, AUC: 0.820523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006304864287376404, AUC: 0.8346720000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006052930355072021, AUC: 0.8673010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007203282117843628, AUC: 0.376063\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006335684955120086, AUC: 0.8234179999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006088856756687164, AUC: 0.8608675\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006270121037960052, AUC: 0.8211750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001696493625640869, AUC: 0.66887\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006789639592170715, AUC: 0.6845829999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006736464202404022, AUC: 0.718854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006768486201763153, AUC: 0.7120259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018442565202713014, AUC: 0.5219509999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006120923459529877, AUC: 0.8202\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000506926953792572, AUC: 0.8859980000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00047893545031547544, AUC: 0.891357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0042138068675994875, AUC: 0.586473\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005170112550258637, AUC: 0.8490500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007585460841655731, AUC: 0.8169130000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008171174228191376, AUC: 0.837557\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005855378389358521, AUC: 0.5729339999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006131704747676849, AUC: 0.8323889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000585062175989151, AUC: 0.789864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005982926189899444, AUC: 0.855815\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009782609045505524, AUC: 0.579432\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006099650859832763, AUC: 0.8342905\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000610582947731018, AUC: 0.8294535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006552601158618927, AUC: 0.7720029999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036024391651153565, AUC: 0.5018050000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009566549360752105, AUC: 0.7762585000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004845850765705109, AUC: 0.877032\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005550507605075836, AUC: 0.8767670000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001471774697303772, AUC: 0.463585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006369509994983673, AUC: 0.835522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006457465887069702, AUC: 0.8334650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006976010799407959, AUC: 0.6949690000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008360674381256103, AUC: 0.459351\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005341401696205139, AUC: 0.8601289999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006089065968990326, AUC: 0.8571650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007155411839485169, AUC: 0.8534649999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0057022528648376465, AUC: 0.443666\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006242684423923493, AUC: 0.7980269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006230420470237732, AUC: 0.8386259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006172062456607819, AUC: 0.8580055\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027160391807556153, AUC: 0.6243945\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006845122277736664, AUC: 0.6798705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007070309817790985, AUC: 0.8357679999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000688802182674408, AUC: 0.86809\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010274484157562255, AUC: 0.43131699999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005393252670764923, AUC: 0.8655510000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000542708158493042, AUC: 0.8785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006341859102249145, AUC: 0.881508\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014589882493019103, AUC: 0.5430969999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006571154296398162, AUC: 0.8273890000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000635101467370987, AUC: 0.873568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008416328430175781, AUC: 0.8715390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009609416723251342, AUC: 0.6767939999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005401946604251861, AUC: 0.871282\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005418049395084381, AUC: 0.8690689999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006961035430431366, AUC: 0.8568899999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009871711730957031, AUC: 0.606004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000656425267457962, AUC: 0.7575879999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006560406684875488, AUC: 0.7748010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006673433780670166, AUC: 0.7665390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009867416322231293, AUC: 0.4824795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006183418035507202, AUC: 0.843547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006091911494731903, AUC: 0.8466259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006658393144607544, AUC: 0.809776\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0037448383569717407, AUC: 0.44409550000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005492468774318695, AUC: 0.866058\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005301939845085144, AUC: 0.880561\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004857119768857956, AUC: 0.8770009999999999\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.003161272644996643, AUC: 0.41251450000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006577843129634858, AUC: 0.7721280000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006510413885116577, AUC: 0.8119590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006834783256053924, AUC: 0.7371965\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007635658979415894, AUC: 0.5259750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006667162775993347, AUC: 0.826497\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00046142929792404174, AUC: 0.8826079999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005662816166877747, AUC: 0.8821570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00527819013595581, AUC: 0.623162\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000671224981546402, AUC: 0.7465020000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006038239300251007, AUC: 0.818011\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006939477026462555, AUC: 0.763509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009949098825454711, AUC: 0.525459\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005505824089050293, AUC: 0.8350599999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006728788614273071, AUC: 0.851826\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007723431885242462, AUC: 0.8627179999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0051541259288787845, AUC: 0.378697\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005366129279136657, AUC: 0.852487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004886251538991928, AUC: 0.877926\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008117223083972931, AUC: 0.8307450000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00716744351387024, AUC: 0.684048\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006961374580860138, AUC: 0.505483\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006554119884967804, AUC: 0.8133100000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005609714984893799, AUC: 0.8666060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.02642657947540283, AUC: 0.4995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006505627036094665, AUC: 0.8181575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006608871817588806, AUC: 0.7992739999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006263557076454162, AUC: 0.85832\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004543404579162597, AUC: 0.631426\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005221415758132935, AUC: 0.862099\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005900335609912873, AUC: 0.8708705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005650161504745483, AUC: 0.875543\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008777439892292023, AUC: 0.558889\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006276139318943023, AUC: 0.819357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006147114932537078, AUC: 0.822582\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006175821721553802, AUC: 0.8205845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001693596303462982, AUC: 0.400595\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006214925050735474, AUC: 0.8365140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000634550154209137, AUC: 0.8329835000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006458875834941864, AUC: 0.8294495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008401041626930237, AUC: 0.45910100000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006550720632076263, AUC: 0.803302\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006291375160217285, AUC: 0.846512\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006445610821247101, AUC: 0.8348575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009529912769794464, AUC: 0.4481195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008605138957500458, AUC: 0.823534\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006922304034233094, AUC: 0.8742650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001038054347038269, AUC: 0.8559889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031378650665283203, AUC: 0.461381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006083640158176422, AUC: 0.8285779999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006089989840984345, AUC: 0.8352750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006090661287307739, AUC: 0.8364674999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016849312782287597, AUC: 0.5514540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006809587180614472, AUC: 0.8517699999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006802175343036651, AUC: 0.872798\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007102130353450775, AUC: 0.8755389999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014982863068580628, AUC: 0.7073149999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006403206586837769, AUC: 0.8286090000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004773274213075638, AUC: 0.8896029999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00045312440395355226, AUC: 0.9010090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013041137456893922, AUC: 0.5622955000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006141194701194763, AUC: 0.8234425\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006080309748649597, AUC: 0.8286015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006125819981098175, AUC: 0.8217569999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003603789210319519, AUC: 0.29629099999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006364342272281646, AUC: 0.8299839999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004765290319919586, AUC: 0.8899015000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006540343761444092, AUC: 0.8887889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004474341869354248, AUC: 0.27523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006286265850067138, AUC: 0.816022\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006146618127822876, AUC: 0.8263\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006142714321613311, AUC: 0.8198240000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013341991305351258, AUC: 0.38203899999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006550778448581695, AUC: 0.7524825000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006494312584400177, AUC: 0.7793775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006254936456680298, AUC: 0.8198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015375759601593017, AUC: 0.5752705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004998665004968643, AUC: 0.8713310000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004558940976858139, AUC: 0.8881680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005193336308002472, AUC: 0.8881379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004447744131088257, AUC: 0.6278139999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006632433235645294, AUC: 0.790051\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006070568263530731, AUC: 0.8536799999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007421883642673492, AUC: 0.813391\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002644798755645752, AUC: 0.37327699999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005455534160137177, AUC: 0.84761\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005088476985692978, AUC: 0.860836\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005386617779731751, AUC: 0.8720860000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008612888753414154, AUC: 0.436357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006472311913967132, AUC: 0.8241080000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005795561671257019, AUC: 0.8602719999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005323151350021362, AUC: 0.8773795000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013507744669914246, AUC: 0.408864\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005396056175231934, AUC: 0.860159\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000493014395236969, AUC: 0.8790829999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00071695476770401, AUC: 0.860284\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015611640810966492, AUC: 0.5225550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006559405922889709, AUC: 0.8092435000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006636940836906433, AUC: 0.8005865\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006353818476200104, AUC: 0.8414540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012031362056732179, AUC: 0.638363\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010520970225334166, AUC: 0.682701\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005199986696243286, AUC: 0.874253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005920561850070953, AUC: 0.869362\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006622237920761108, AUC: 0.33296800000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006453602910041809, AUC: 0.791797\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006511553525924683, AUC: 0.8013290000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000625989556312561, AUC: 0.8411319999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009378238618373871, AUC: 0.39687399999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006321190893650055, AUC: 0.8370919999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006297567486763001, AUC: 0.8095295\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006020152270793914, AUC: 0.8341049999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000758861094713211, AUC: 0.596522\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006415611207485199, AUC: 0.8028650000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006537134945392609, AUC: 0.8407749999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006202761530876159, AUC: 0.833253\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003642560839653015, AUC: 0.375499\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006914866864681244, AUC: 0.5368775\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006934985518455506, AUC: 0.5000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006945231854915618, AUC: 0.507504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009397297799587249, AUC: 0.409401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005670367181301117, AUC: 0.843205\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005706052780151367, AUC: 0.8630240000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004942325055599212, AUC: 0.8598049999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001518834888935089, AUC: 0.5165249999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006561667621135712, AUC: 0.8033915\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006600448787212372, AUC: 0.8036585\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006707564294338226, AUC: 0.8111705\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009831798553466798, AUC: 0.4117655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005761415660381317, AUC: 0.855991\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006893740892410278, AUC: 0.8189139999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005601320862770081, AUC: 0.8692980000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00261846125125885, AUC: 0.5577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006089528501033783, AUC: 0.838268\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006422235369682312, AUC: 0.825171\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011870046257972718, AUC: 0.8056099999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015995723605155944, AUC: 0.4268235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005534631311893463, AUC: 0.865054\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005400881469249725, AUC: 0.8696229999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006624490320682525, AUC: 0.835174\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015393699407577515, AUC: 0.4664165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006816013753414154, AUC: 0.5793659999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006377974450588226, AUC: 0.852177\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009263686835765839, AUC: 0.8521740000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013302900195121764, AUC: 0.429821\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005070193409919739, AUC: 0.867448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005645208358764648, AUC: 0.8671650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005875370800495148, AUC: 0.871914\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017066441774368287, AUC: 0.46097600000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000631738156080246, AUC: 0.8199730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000568773090839386, AUC: 0.823789\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004979112595319748, AUC: 0.8687514999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.025624692916870116, AUC: 0.497503\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006828151941299438, AUC: 0.627961\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006645142138004303, AUC: 0.7161415000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006535460650920867, AUC: 0.7628929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007037867307662964, AUC: 0.417947\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007242453098297119, AUC: 0.8220524999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006587843298912048, AUC: 0.7627690000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006124875545501709, AUC: 0.839073\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022088483572006226, AUC: 0.3945169999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005370227694511413, AUC: 0.8342769999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009256865680217743, AUC: 0.8256240000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00045700226724147794, AUC: 0.8799370000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018247625827789308, AUC: 0.643813\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000632505714893341, AUC: 0.806931\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006392984688282013, AUC: 0.8195220000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006412795782089234, AUC: 0.828493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011819305419921875, AUC: 0.379614\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006331652402877808, AUC: 0.8338570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005659005045890808, AUC: 0.858886\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006737819015979766, AUC: 0.8523005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033760460615158082, AUC: 0.43174599999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006505196392536163, AUC: 0.80306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006508789956569672, AUC: 0.7968669999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006723713576793671, AUC: 0.7920499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003379668712615967, AUC: 0.6039999999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000616830587387085, AUC: 0.8451644999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005418446362018585, AUC: 0.870398\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000647581398487091, AUC: 0.85778\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020687575340270995, AUC: 0.6241730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006761561930179596, AUC: 0.7221325000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006462470591068268, AUC: 0.797411\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006670638024806976, AUC: 0.7695585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0027069926261901857, AUC: 0.271301\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006277077496051788, AUC: 0.829559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006772807836532593, AUC: 0.7284229999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005778884291648865, AUC: 0.8854779999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033161873817443848, AUC: 0.510144\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005958463251590729, AUC: 0.8321669999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010944167971611023, AUC: 0.8297680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00048611439764499663, AUC: 0.88657\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004520923614501953, AUC: 0.6438010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006494361758232117, AUC: 0.785521\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006225666999816894, AUC: 0.8334165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005736533999443055, AUC: 0.8663160000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009794733226299287, AUC: 0.558621\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006236424148082733, AUC: 0.7910160000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006647404730319977, AUC: 0.7853819999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006243115663528442, AUC: 0.832504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000971899688243866, AUC: 0.517507\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005190590023994446, AUC: 0.8712429999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007121954262256622, AUC: 0.875333\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005055973380804062, AUC: 0.885644\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.009436395168304443, AUC: 0.697322\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000477787122130394, AUC: 0.8650725000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006966128647327423, AUC: 0.872519\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000709657609462738, AUC: 0.8777\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003092007517814636, AUC: 0.4520855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006755298972129822, AUC: 0.723294\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006167215704917907, AUC: 0.8331430000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005964199602603912, AUC: 0.850885\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008606303334236145, AUC: 0.47664400000000007\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004919575899839401, AUC: 0.879121\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005770783722400665, AUC: 0.884413\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004778592586517334, AUC: 0.8782329999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022661025524139404, AUC: 0.3880199999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006345840096473694, AUC: 0.8269495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000627483606338501, AUC: 0.8335885000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006071146130561828, AUC: 0.8506990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008095745742321014, AUC: 0.617745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006692566275596619, AUC: 0.8711110000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005056192129850388, AUC: 0.884113\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006050131022930145, AUC: 0.8821489999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010582844614982604, AUC: 0.434825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006321779787540436, AUC: 0.8371109999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006425855457782746, AUC: 0.8259259999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006508597135543823, AUC: 0.8274239999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002170096158981323, AUC: 0.422222\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005434127748012542, AUC: 0.841921\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005767458379268646, AUC: 0.8605039999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008864089548587799, AUC: 0.8463620000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000889493465423584, AUC: 0.6056060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006578434705734252, AUC: 0.771805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000651656836271286, AUC: 0.7912310000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007088583409786224, AUC: 0.612181\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007673566341400147, AUC: 0.582547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000660072237253189, AUC: 0.806076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008888261914253235, AUC: 0.8398539999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006505318880081177, AUC: 0.862181\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002117843270301819, AUC: 0.6092460000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006709987223148346, AUC: 0.7336860000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005301750302314759, AUC: 0.8578619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010735006928443908, AUC: 0.7268195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003707240581512451, AUC: 0.6446930000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007216502130031585, AUC: 0.8434504999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013948171734809876, AUC: 0.8321670000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008669805526733399, AUC: 0.880719\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005251201152801513, AUC: 0.6490170000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006337235271930695, AUC: 0.813069\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006640153527259826, AUC: 0.789005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006715028882026673, AUC: 0.7827155\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010522256493568421, AUC: 0.534693\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006465831995010376, AUC: 0.802291\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006500383615493775, AUC: 0.7805845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000675906240940094, AUC: 0.7388090000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011087210178375244, AUC: 0.6278115\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005141288638114929, AUC: 0.8803750000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006745084524154663, AUC: 0.8822060000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009938264191150666, AUC: 0.873124\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016988049745559693, AUC: 0.5635330000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006558447182178497, AUC: 0.7788655000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000636860877275467, AUC: 0.839542\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000644484668970108, AUC: 0.873401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0029737695455551148, AUC: 0.4846755\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004959933757781983, AUC: 0.8758\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009878093600273132, AUC: 0.8573959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044674426317214966, AUC: 0.8777995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014749653935432433, AUC: 0.38021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006421972215175628, AUC: 0.8261245\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006367229223251343, AUC: 0.8402395000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006055663228034973, AUC: 0.8516545\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010789324045181274, AUC: 0.487966\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005993645191192627, AUC: 0.8573780000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006934288144111633, AUC: 0.804652\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006928565800189972, AUC: 0.8325089999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008963207244873046, AUC: 0.292893\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006307980716228485, AUC: 0.8409975000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044097155332565305, AUC: 0.893387\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006107635796070099, AUC: 0.883138\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018931411504745483, AUC: 0.436731\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005886760354042053, AUC: 0.8432600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005124597549438476, AUC: 0.8542150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007622775137424469, AUC: 0.854518\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008213213920593262, AUC: 0.5389269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005990959703922272, AUC: 0.855619\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006890757977962493, AUC: 0.8809600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005154180824756623, AUC: 0.842367\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005599292516708374, AUC: 0.51523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004924837797880173, AUC: 0.871112\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008774142265319824, AUC: 0.8659570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008101040720939636, AUC: 0.8761519999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0038461780548095705, AUC: 0.39699700000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000572138249874115, AUC: 0.853536\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009171148836612701, AUC: 0.835097\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006680074632167816, AUC: 0.8727969999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013353575468063354, AUC: 0.5505610000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005155101716518403, AUC: 0.884812\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007372788488864899, AUC: 0.8651510000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009411675035953522, AUC: 0.8739500000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001936394214630127, AUC: 0.517002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000666076809167862, AUC: 0.7686590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007068905830383301, AUC: 0.7270385\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007179478704929351, AUC: 0.7726339999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0052087240219116215, AUC: 0.634559\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006727664470672607, AUC: 0.7903570000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006739646792411804, AUC: 0.8188945000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000683035284280777, AUC: 0.838019\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005699269771575928, AUC: 0.6936499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005435561239719391, AUC: 0.876919\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008543529510498047, AUC: 0.864314\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010324636697769166, AUC: 0.8586935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002568994998931885, AUC: 0.575228\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00061638343334198, AUC: 0.851312\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000751068651676178, AUC: 0.8534499999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006772048175334931, AUC: 0.853453\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0020747926831245424, AUC: 0.538002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006125572025775909, AUC: 0.845891\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007022102177143097, AUC: 0.854166\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000546689659357071, AUC: 0.884897\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017113133668899536, AUC: 0.3844615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006050582528114318, AUC: 0.850267\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006217851340770722, AUC: 0.848304\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007419843673706055, AUC: 0.8304939999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005215336799621582, AUC: 0.4443845\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006739299297332763, AUC: 0.7537320000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007184376120567322, AUC: 0.8207819999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010124845504760741, AUC: 0.8137429999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006814226150512696, AUC: 0.32473149999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006066479086875915, AUC: 0.843904\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000612095981836319, AUC: 0.8383875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006303972005844116, AUC: 0.835602\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010880833864212035, AUC: 0.600568\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009221643507480622, AUC: 0.448176\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006421560943126679, AUC: 0.802567\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006896566450595856, AUC: 0.7568725000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00091671884059906, AUC: 0.6356554999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006143573224544525, AUC: 0.8466174999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005997539162635803, AUC: 0.844641\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006789544224739075, AUC: 0.8123530000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00218618905544281, AUC: 0.617639\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006320583522319794, AUC: 0.8401510000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006620469093322754, AUC: 0.8284904999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007420209050178528, AUC: 0.723021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028511924743652344, AUC: 0.4868795\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006685357093811035, AUC: 0.7732895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006482214629650116, AUC: 0.838779\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006847953200340271, AUC: 0.8263130000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.007305559396743775, AUC: 0.34596649999999995\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006561188697814941, AUC: 0.7805110000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005917318165302276, AUC: 0.8624375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943855881690979, AUC: 0.775289\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0017351108193397523, AUC: 0.4362275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006127724349498749, AUC: 0.8488074999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006939322948455811, AUC: 0.697855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000645067036151886, AUC: 0.8413845000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001088395893573761, AUC: 0.623601\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006588148176670074, AUC: 0.6967530000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005927228033542633, AUC: 0.8619805\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004840468168258667, AUC: 0.881261\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015400919914245604, AUC: 0.38641800000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006672055423259736, AUC: 0.7549925\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006555777490139008, AUC: 0.810179\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007266658842563629, AUC: 0.692265\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034725695848464968, AUC: 0.6797759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006258465945720673, AUC: 0.8221355000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006342698335647583, AUC: 0.8457009999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000707786351442337, AUC: 0.8364940000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009621517062187195, AUC: 0.5690394999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005215201079845429, AUC: 0.866564\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014242846369743347, AUC: 0.8417990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008070301413536071, AUC: 0.8736499999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009343173801898957, AUC: 0.56377\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006375585794448853, AUC: 0.8427680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006376972794532776, AUC: 0.8419009999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005580554008483887, AUC: 0.8664229999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031886664628982546, AUC: 0.488541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005492565333843232, AUC: 0.86645\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007887198328971862, AUC: 0.854996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001674716532230377, AUC: 0.824076\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013313739895820618, AUC: 0.460017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00059758061170578, AUC: 0.8346155\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.00048768319189548495, AUC: 0.878092\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044023710489273074, AUC: 0.892667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016253237724304199, AUC: 0.531132\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006592078804969788, AUC: 0.8558719999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006208440065383911, AUC: 0.870744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006931117773056031, AUC: 0.8311540000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056273510456085205, AUC: 0.3395535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006935471892356872, AUC: 0.49993350000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000693195253610611, AUC: 0.500504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009124216139316559, AUC: 0.820488\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001134386420249939, AUC: 0.5104730000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000614866316318512, AUC: 0.8556785000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006206272244453431, AUC: 0.856273\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000652146726846695, AUC: 0.858349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009268079102039337, AUC: 0.508106\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005959088802337646, AUC: 0.870487\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006989267766475678, AUC: 0.8382099999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005956757068634034, AUC: 0.891509\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003956462025642395, AUC: 0.40340250000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006428180038928986, AUC: 0.8126495000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007155625522136688, AUC: 0.695198\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005982469618320465, AUC: 0.85024\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005729780912399292, AUC: 0.606244\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006691626012325287, AUC: 0.7376140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006667289733886719, AUC: 0.778287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006954544186592102, AUC: 0.7813825000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001550057351589203, AUC: 0.423467\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011788462996482848, AUC: 0.799323\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006453268826007843, AUC: 0.875145\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006750417947769165, AUC: 0.870437\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012183114886283875, AUC: 0.5099435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006025969088077545, AUC: 0.8633820000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006281567215919494, AUC: 0.8731684999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000670610100030899, AUC: 0.8773779999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004821844100952148, AUC: 0.7064779999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005366271138191223, AUC: 0.868745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004981711953878403, AUC: 0.8734649999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006779168248176575, AUC: 0.87881\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000833460420370102, AUC: 0.547554\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007388848066329956, AUC: 0.812049\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000594251662492752, AUC: 0.873225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007500885426998138, AUC: 0.883627\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0030993087291717528, AUC: 0.421025\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00060576993227005, AUC: 0.8482519999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006173049509525299, AUC: 0.8602195\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006135944724082946, AUC: 0.861665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012295038700103759, AUC: 0.569275\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006493670046329498, AUC: 0.8517820000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000639921247959137, AUC: 0.8569875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006539488434791565, AUC: 0.8601850000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014329693913459778, AUC: 0.6865460000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007035166621208191, AUC: 0.882829\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00047143684327602387, AUC: 0.883983\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006800387203693389, AUC: 0.895889\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010066055953502654, AUC: 0.35892799999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007146929800510406, AUC: 0.827547\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006267230212688446, AUC: 0.8598759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005338139832019806, AUC: 0.852396\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019196035861968994, AUC: 0.469584\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006251118183135987, AUC: 0.8485885000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006656976640224457, AUC: 0.816202\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007135991752147675, AUC: 0.7457119999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001229893207550049, AUC: 0.4001035\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006900463104248047, AUC: 0.6499269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007012208700180054, AUC: 0.721734\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007067648768424988, AUC: 0.7993359999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005733465194702149, AUC: 0.50572\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006741888225078583, AUC: 0.7686600000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006162460744380951, AUC: 0.8492140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007225070893764495, AUC: 0.7712384999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0056755318641662595, AUC: 0.4878475\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006561889350414276, AUC: 0.8174405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000689521849155426, AUC: 0.785948\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007216289341449737, AUC: 0.7878390000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014051686525344848, AUC: 0.33911900000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008266070485115052, AUC: 0.83235\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006753382682800293, AUC: 0.877177\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009543298482894897, AUC: 0.857096\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003067035436630249, AUC: 0.541655\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00061040198802948, AUC: 0.8499745000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006265634894371033, AUC: 0.8579640000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006277212202548981, AUC: 0.8693025000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010460501313209534, AUC: 0.5601590000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006805631518363953, AUC: 0.7259015\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006743496656417846, AUC: 0.821445\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006699684262275696, AUC: 0.8488555\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011528522968292235, AUC: 0.596535\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006797283291816712, AUC: 0.6920860000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008381953835487365, AUC: 0.79226\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006819453239440918, AUC: 0.8783359999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014674580097198487, AUC: 0.41800499999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006332810223102569, AUC: 0.766872\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006441789269447327, AUC: 0.8211665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006571180522441865, AUC: 0.8478485000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.014502759456634522, AUC: 0.667986\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000645201563835144, AUC: 0.8306285000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005786017477512359, AUC: 0.847216\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000678882896900177, AUC: 0.8400585\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002010072946548462, AUC: 0.5741505\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006650691628456116, AUC: 0.7625255000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000672869861125946, AUC: 0.7770455\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006971729099750519, AUC: 0.7876884999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001130767285823822, AUC: 0.523094\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006292125284671783, AUC: 0.8130264999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005771870613098145, AUC: 0.8615410000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005784543454647064, AUC: 0.873416\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014317245483398437, AUC: 0.580156\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012079253196716308, AUC: 0.8306150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009267065525054932, AUC: 0.882379\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005733566880226135, AUC: 0.8930869999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0063600332736968995, AUC: 0.29085950000000005\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006122156381607055, AUC: 0.846581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005798280239105224, AUC: 0.8395594999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000650407463312149, AUC: 0.8395615\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028655608892440795, AUC: 0.368576\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005464257299900055, AUC: 0.8709769999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006439199447631836, AUC: 0.8857360000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006710804104804993, AUC: 0.773527\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019567331075668335, AUC: 0.600349\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006273092031478882, AUC: 0.81254\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005499212145805359, AUC: 0.8667864999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007687760293483734, AUC: 0.8747379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010839694142341615, AUC: 0.47224499999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005068928450345993, AUC: 0.879897\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005407334864139557, AUC: 0.889702\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005212968289852142, AUC: 0.890093\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0028057591915130616, AUC: 0.3861495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006564192473888398, AUC: 0.8159625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006895624101161957, AUC: 0.8010490000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007369867265224456, AUC: 0.7629954999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012457998394966125, AUC: 0.555586\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006952352225780488, AUC: 0.65932\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006939291656017304, AUC: 0.7795179999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007086337804794312, AUC: 0.794881\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0019257506132125855, AUC: 0.454948\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006175247728824615, AUC: 0.8016159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006350263059139252, AUC: 0.799287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006606808602809906, AUC: 0.791172\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008123100697994232, AUC: 0.6383375\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006826936006546021, AUC: 0.708519\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000645332008600235, AUC: 0.8176844999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006571354866027832, AUC: 0.81378\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001607116162776947, AUC: 0.379599\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006350829601287842, AUC: 0.820282\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009689815044403076, AUC: 0.819491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008803562819957733, AUC: 0.8266849999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0022125324010849, AUC: 0.6484825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006395947635173798, AUC: 0.8270935\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005076109170913697, AUC: 0.8606119999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005843505561351776, AUC: 0.8344165\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012342700362205506, AUC: 0.35495750000000004\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006355985701084137, AUC: 0.821177\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006616105139255524, AUC: 0.8193134999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007040329873561859, AUC: 0.7981135\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007877288460731507, AUC: 0.6318085\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006132458746433258, AUC: 0.8551420000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000590732455253601, AUC: 0.8589859999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007146210670471192, AUC: 0.8049545000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010239960551261902, AUC: 0.5964780000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006309909522533417, AUC: 0.837091\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006747953593730927, AUC: 0.7999515000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000735415130853653, AUC: 0.738527\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0014923771023750306, AUC: 0.6283690000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00047614987194538117, AUC: 0.8785089999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000806472510099411, AUC: 0.8678\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005012668520212174, AUC: 0.886154\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0015819613337516784, AUC: 0.7592960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004978864789009094, AUC: 0.88191\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005415335893630981, AUC: 0.8899329999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005519392490386963, AUC: 0.8900239999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036699886322021486, AUC: 0.320017\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006221868097782135, AUC: 0.865207\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005562796294689179, AUC: 0.8629189999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006654063761234283, AUC: 0.8798910000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0034238733053207396, AUC: 0.637479\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005064839422702789, AUC: 0.8712859999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005074124932289123, AUC: 0.873943\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005217430740594864, AUC: 0.860831\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.01035306978225708, AUC: 0.6743085000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00045594637095928194, AUC: 0.8926949999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004405239075422287, AUC: 0.8995365\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00039464974403381346, AUC: 0.90495\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005660022258758545, AUC: 0.411311\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006519597470760345, AUC: 0.805799\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000596570909023285, AUC: 0.8610290000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007281141281127929, AUC: 0.7076220000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0031654269695281984, AUC: 0.4150465\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005891810059547424, AUC: 0.84287\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006235306859016419, AUC: 0.810397\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006508610546588898, AUC: 0.8023710000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002578646540641785, AUC: 0.4273405\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005713171660900116, AUC: 0.8752740000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005508973598480224, AUC: 0.855875\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012370412349700928, AUC: 0.827745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.004851328372955322, AUC: 0.514306\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006682078838348388, AUC: 0.718581\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005894941985607147, AUC: 0.8705970000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00069499871134758, AUC: 0.81034\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001334623396396637, AUC: 0.45214\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000641354113817215, AUC: 0.832003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006543030738830566, AUC: 0.8377825\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006602018475532532, AUC: 0.850724\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0016858134269714356, AUC: 0.6857665\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006079002618789673, AUC: 0.858922\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006103567779064178, AUC: 0.8589349999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007017521560192108, AUC: 0.78276\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.005432530403137207, AUC: 0.6226720000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006614299118518829, AUC: 0.7851985000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000676672488451004, AUC: 0.782594\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007210492193698883, AUC: 0.706504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0012225557565689086, AUC: 0.308937\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006119610667228699, AUC: 0.8543990000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006763741970062256, AUC: 0.8123325000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006945586204528809, AUC: 0.7983159999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010329886436462403, AUC: 0.46101200000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006103428900241851, AUC: 0.8377995000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006347467303276062, AUC: 0.8159325\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006485618650913239, AUC: 0.8041720000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008546455502510071, AUC: 0.60593\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000583718478679657, AUC: 0.8491069999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005297510027885437, AUC: 0.8729100000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006022444665431977, AUC: 0.8328530000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0021111356019973757, AUC: 0.560248\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000677774578332901, AUC: 0.6981870000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006644289195537567, AUC: 0.7678800000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006877001523971557, AUC: 0.7402460000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0018432533144950866, AUC: 0.588681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006500774621963501, AUC: 0.8329030000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006531818807125092, AUC: 0.8431315000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007269009947776794, AUC: 0.7777044999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010021627843379973, AUC: 0.599874\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006994208097457886, AUC: 0.8719140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004926715195178985, AUC: 0.8669020000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001104572355747223, AUC: 0.8656619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.008520609378814697, AUC: 0.598482\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005430616736412048, AUC: 0.877435\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005804557800292969, AUC: 0.872288\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007609830200672149, AUC: 0.864444\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.006490588426589966, AUC: 0.6882280000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007000972330570221, AUC: 0.86488\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00047880475223064425, AUC: 0.8819890000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007516524195671082, AUC: 0.863839\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.010153179168701171, AUC: 0.43023999999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006573152840137482, AUC: 0.7844650000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007127955555915833, AUC: 0.6794729999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006700641512870788, AUC: 0.8364179999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010497003197669982, AUC: 0.494504\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006012768149375916, AUC: 0.81895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000597824364900589, AUC: 0.8145010000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006380328536033631, AUC: 0.7971039999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0036309754848480227, AUC: 0.5306025000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006941179037094116, AUC: 0.5506850000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006257172226905823, AUC: 0.8204824999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006724870800971984, AUC: 0.7805150000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.003862712502479553, AUC: 0.4114915\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006394362151622773, AUC: 0.8318735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006617222726345062, AUC: 0.8666920000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007403411865234375, AUC: 0.8690680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0013845330476760865, AUC: 0.5036105\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006082592308521271, AUC: 0.845541\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005472329258918762, AUC: 0.865144\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006499690711498261, AUC: 0.8656619999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0010931934118270873, AUC: 0.329523\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006692779362201691, AUC: 0.840603\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008829580843448639, AUC: 0.8413059999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006391588747501374, AUC: 0.802193\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.002035938858985901, AUC: 0.336951\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006522195637226105, AUC: 0.872225\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.001666193962097168, AUC: 0.825898\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009747958779335022, AUC: 0.8789880000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0009209502041339874, AUC: 0.40136600000000006\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006521264910697937, AUC: 0.815193\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000580347865819931, AUC: 0.8574335\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005380468666553497, AUC: 0.8669525\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011348304152488707, AUC: 0.44075899999999996\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005707217752933502, AUC: 0.877923\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006282792389392853, AUC: 0.850673\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006381843984127045, AUC: 0.8503809999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0033856658935546876, AUC: 0.6792895\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000523179978132248, AUC: 0.885481\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005394602417945862, AUC: 0.8637460000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005314507186412811, AUC: 0.8687680000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0011252643465995789, AUC: 0.630936\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006328122019767761, AUC: 0.8492880000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005822356343269348, AUC: 0.8679219999999997\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000679804265499115, AUC: 0.8545080000000003\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007880481481552125, AUC: 0.52401\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006189630329608918, AUC: 0.844381\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007531801462173462, AUC: 0.8698409999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0008655894994735718, AUC: 0.8505590000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cosine distance + capped loss using whole class average tensor\n",
    "momentum=0\n",
    "learning_rates = [5e-4, 1e-3]\n",
    "\n",
    "\n",
    "cap_aucs=[]\n",
    "\n",
    "    \n",
    "loss_fn_args = {}\n",
    "loss_caps = [0.75]\n",
    "loss_fn_args['distance'] = 'cosine'\n",
    "\n",
    "start_epoch = 2\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for loss_cap in loss_caps:\n",
    "    \n",
    "    learning_rate_aucs = []\n",
    "    \n",
    "    for learning_rate in learning_rates:\n",
    "        aucs = []\n",
    "        for i in range(100):\n",
    "            model_aucs = []\n",
    "            network = models.ConvNetWithEmbeddingsEarly(NUM_CLASSES_REDUCED)\n",
    "            optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "            _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network, embeddings=True) \n",
    "            model_aucs.append(auc)\n",
    "            for epoch in range(start_epoch):\n",
    "                loss_fn_args['loss_cap'] = None\n",
    "                loss_fn_args['avg_tensors'] = None\n",
    "                _, _ = train.train_sigmoid_with_embeddings(epoch, train_loader_smote, network, optimizer, verbose=False,loss_fn=loss_fns.CappedBCELossAvgDistance,loss_fn_args=loss_fn_args)\n",
    "            for epoch in range(start_epoch, n_epochs + 1):\n",
    "                loss_fn_args['loss_cap'] = loss_cap\n",
    "                loss_fn_args['print_loss']= False\n",
    "                loss_fn_args['avg_tensors'] = []\n",
    "                for k in range(NUM_CLASSES_REDUCED):\n",
    "                    _, avg_tensor = network(avg_tensors_list[k])\n",
    "                    loss_fn_args['avg_tensors'].append(avg_tensor)\n",
    "                _, _ = train.train_sigmoid_with_embeddings(epoch, train_loader_smote, network, optimizer, verbose=False, loss_fn=loss_fns.CappedBCELossAvgDistance, loss_fn_args=loss_fn_args)\n",
    "                if (epoch + 1) % 10 == 0: \n",
    "                    _, auc = metric_utils.auc_sigmoid(test_loader_reduced, network, embeddings=True)\n",
    "                    model_aucs.append(auc)\n",
    "            aucs.append(model_aucs)\n",
    "        learning_rate_aucs.append(aucs)\n",
    "\n",
    "    learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "    auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "    auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "        \n",
    "    cap_aucs.append([auc_mean, auc_variance])\n",
    "\n",
    "for c in range(len(cap_aucs)):\n",
    "    auc_mean = cap_aucs[c][0]\n",
    "    auc_variance = cap_aucs[c][1]\n",
    "    cap = loss_caps[c]\n",
    "    for i in range(len(learning_rates)): \n",
    "        row = [\"cosine_distance_capped_smote_avg\", 2, nums, ratio, learning_rates[i],\n",
    "                auc_mean[i][0], auc_variance[i][0], \n",
    "                auc_mean[i][1], auc_variance[i][1],\n",
    "                auc_mean[i][2], auc_variance[i][2],\n",
    "                auc_mean[i][3], auc_variance[i][3], cap, norm, 'num_models=100']\n",
    "        rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "deb3dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee3c527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# triplet loss smote + no smote training \n",
    "\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [(5e-6, 5e-3), (1e-6, 1e-2), (5e-6, 1e-3), (1e-6, 5e-4)]\n",
    "\n",
    "loss_fn_args = {}\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "\n",
    "start_epoch = 10\n",
    "\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10): \n",
    "        model_aucs = []\n",
    "        embed_network = models.ConvNetOnlyEmbeddingsEarly(2)\n",
    "        linear_probe = models.ConvNetLinearProbeEarly(2)\n",
    "        complete_network = models.CompleteConvNet(embed_network, linear_probe)\n",
    "        embed_optimizer = optim.SGD(embed_network.parameters(), lr=learning_rate[0], momentum=momentum)\n",
    "        linear_optimizer = optim.SGD(complete_network.parameters(), lr=learning_rate[1], momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(start_epoch):\n",
    "            _, train_losses = train.train_triplet_loss_smote(epoch, train_loader_tripletloss_smote, embed_network, embed_optimizer, verbose=False)\n",
    "            print(\"Train loss: \" + str(np.mean(np.array(train_losses))))\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                model_aucs.append(auc) \n",
    "        for epoch in range(start_epoch, n_epochs+1):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_ratio, complete_network, linear_optimizer, verbose=False, loss_fn_args=loss_fn_args)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                model_aucs.append(auc) \n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "\n",
    "\n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss_first_stage_smote\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], None, norm, \"start_epoch=10\"]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7063b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss_first_stage_smote\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], cap, norm, \"start_epoch=10\"]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9c0a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss_first_stage_smote\", 2, nums, ratio, learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], None, norm, \"start_epoch=10\"]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16529511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46c875a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0006957003772258758, AUC: 0.39529899999999996\n",
      "\n",
      "Train loss: 2.310011562648093\n",
      "Train loss: 2.2350221542036457\n",
      "Train loss: 1.7336593600595074\n",
      "Train loss: 1.3570892761467368\n",
      "Train loss: 1.7184112235239357\n",
      "Train loss: 1.1358157290015252\n",
      "Train loss: 1.0679599012538885\n",
      "Train loss: 0.921282701431566\n",
      "Train loss: 1.1848033970328653\n",
      "Train loss: 0.9810460426245525\n",
      "Train loss: 0.9329271555706194\n",
      "Train loss: 0.9048631927769655\n",
      "Train loss: 0.5647244722979843\n",
      "Train loss: 0.5945013852635767\n",
      "Train loss: 0.5329235454273832\n",
      "\n",
      "Test set: Avg. loss: 0.00039782971143722536, AUC: 0.918406\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004035674780607224, AUC: 0.927185\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037781354784965514, AUC: 0.935988\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006927546858787537, AUC: 0.530769\n",
      "\n",
      "Train loss: 2.022161154610336\n",
      "Train loss: 1.288486762031628\n",
      "Train loss: 1.399418694957806\n",
      "Train loss: 1.0709760223224665\n",
      "Train loss: 0.8879150535650314\n",
      "Train loss: 0.994375331386639\n",
      "Train loss: 0.9763853713205666\n",
      "Train loss: 0.5693383987542171\n",
      "Train loss: 0.9217924274456729\n",
      "Train loss: 0.8383852824284013\n",
      "Train loss: 0.8140671158292491\n",
      "Train loss: 0.5722766241450219\n",
      "Train loss: 0.6047726167235404\n",
      "Train loss: 0.7253834802633637\n",
      "Train loss: 0.4782866505300923\n",
      "\n",
      "Test set: Avg. loss: 0.00043531887233257295, AUC: 0.902573\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000422521635890007, AUC: 0.9201060000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003795756101608276, AUC: 0.934749\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006942583620548248, AUC: 0.502446\n",
      "\n",
      "Train loss: 1.7677589347408076\n",
      "Train loss: 1.8473584458326837\n",
      "Train loss: 1.7053442684708127\n",
      "Train loss: 1.416161296853594\n",
      "Train loss: 1.141511501400334\n",
      "Train loss: 1.1581196515423477\n",
      "Train loss: 0.9427745911725767\n",
      "Train loss: 1.0230498211399006\n",
      "Train loss: 0.6721523760989973\n",
      "Train loss: 0.5520871099393079\n",
      "Train loss: 0.8345379647175977\n",
      "Train loss: 0.9725911567924889\n",
      "Train loss: 0.5424710143903259\n",
      "Train loss: 0.5316900049045588\n",
      "Train loss: 0.5941856465521892\n",
      "\n",
      "Test set: Avg. loss: 0.00041989779472351076, AUC: 0.9123869999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003987732827663422, AUC: 0.9274910000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003638770878314972, AUC: 0.9362480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000689285546541214, AUC: 0.687736\n",
      "\n",
      "Train loss: 1.495846663311029\n",
      "Train loss: 1.267180768547544\n",
      "Train loss: 1.6462099081391741\n",
      "Train loss: 1.0757786248140275\n",
      "Train loss: 1.1906113187978222\n",
      "Train loss: 0.8177587450689571\n",
      "Train loss: 0.8175334740596213\n",
      "Train loss: 0.7203467036508451\n",
      "Train loss: 0.6773714051125156\n",
      "Train loss: 0.5988440695841601\n",
      "Train loss: 0.7361402386313032\n",
      "Train loss: 0.42098387335516085\n",
      "Train loss: 0.5238839247424132\n",
      "Train loss: 0.31308006405071087\n",
      "Train loss: 0.4069526119596639\n",
      "\n",
      "Test set: Avg. loss: 0.00043320918083190917, AUC: 0.9107480000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000422193244099617, AUC: 0.9187759999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035831086337566374, AUC: 0.9378759999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006949281096458436, AUC: 0.48180999999999996\n",
      "\n",
      "Train loss: 1.8548816784172302\n",
      "Train loss: 1.3863887054145716\n",
      "Train loss: 1.6101639115127029\n",
      "Train loss: 1.7781756565828992\n",
      "Train loss: 1.1052604218956772\n",
      "Train loss: 0.9795122097252281\n",
      "Train loss: 0.8326696856006696\n",
      "Train loss: 0.9085525866526707\n",
      "Train loss: 0.9520809946546129\n",
      "Train loss: 0.7201870577350543\n",
      "Train loss: 0.6012145732618441\n",
      "Train loss: 0.5797658304499972\n",
      "Train loss: 0.5518804967023765\n",
      "Train loss: 0.5310744734326746\n",
      "Train loss: 0.5478573209920506\n",
      "\n",
      "Test set: Avg. loss: 0.000391305685043335, AUC: 0.918516\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037205873429775236, AUC: 0.9313560000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00034368816018104554, AUC: 0.9376550000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007059581279754639, AUC: 0.2546945\n",
      "\n",
      "Train loss: 1.032807933297127\n",
      "Train loss: 0.8298509728377033\n",
      "Train loss: 0.7243748519830643\n",
      "Train loss: 1.0180361548047157\n",
      "Train loss: 0.9950011934444403\n",
      "Train loss: 0.5970637957761242\n",
      "Train loss: 0.632870893569509\n",
      "Train loss: 0.6421500805077279\n",
      "Train loss: 0.3735534647467789\n",
      "Train loss: 0.5433057603562713\n",
      "Train loss: 0.3770814678471559\n",
      "Train loss: 0.47836669994767306\n",
      "Train loss: 0.5512357597138472\n",
      "Train loss: 0.3627752711059182\n",
      "Train loss: 0.4186748475026173\n",
      "\n",
      "Test set: Avg. loss: 0.0004021726548671722, AUC: 0.914386\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003833182901144028, AUC: 0.929598\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003662377893924713, AUC: 0.9335450000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006975426971912384, AUC: 0.3909895\n",
      "\n",
      "Train loss: 2.0770836582609045\n",
      "Train loss: 1.954999076712663\n",
      "Train loss: 1.2597821559875635\n",
      "Train loss: 1.1962599200048265\n",
      "Train loss: 1.8015421294862297\n",
      "Train loss: 1.2269869610002846\n",
      "Train loss: 1.1497848254100533\n",
      "Train loss: 0.8856590412984229\n",
      "Train loss: 1.0465123585075329\n",
      "Train loss: 0.9539744850176914\n",
      "Train loss: 0.8811213328580189\n",
      "Train loss: 0.7094797613514456\n",
      "Train loss: 0.6675684330569711\n",
      "Train loss: 0.8660271084232695\n",
      "Train loss: 0.7509766274197086\n",
      "\n",
      "Test set: Avg. loss: 0.00043649809062480926, AUC: 0.906458\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003919942080974579, AUC: 0.930021\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035204361379146575, AUC: 0.93962\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006841252148151398, AUC: 0.728719\n",
      "\n",
      "Train loss: 2.792424700442393\n",
      "Train loss: 1.6395947238442246\n",
      "Train loss: 1.7805285658805994\n",
      "Train loss: 1.4789784265931245\n",
      "Train loss: 1.5566897787106264\n",
      "Train loss: 1.299844227019389\n",
      "Train loss: 0.7196527795427164\n",
      "Train loss: 0.9572801836736643\n",
      "Train loss: 1.2006448780655101\n",
      "Train loss: 1.20849530977808\n",
      "Train loss: 0.9535093223972685\n",
      "Train loss: 0.7700273618576633\n",
      "Train loss: 0.44269351480872765\n",
      "Train loss: 0.70063233717232\n",
      "Train loss: 0.6761433846631627\n",
      "\n",
      "Test set: Avg. loss: 0.000415567085146904, AUC: 0.918102\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037865456938743593, AUC: 0.9287039999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00039964130520820615, AUC: 0.934788\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007041244804859161, AUC: 0.3282575\n",
      "\n",
      "Train loss: 1.9345506889045618\n",
      "Train loss: 2.239732494020158\n",
      "Train loss: 1.3338085925503143\n",
      "Train loss: 1.2418701041276288\n",
      "Train loss: 1.0202735499211937\n",
      "Train loss: 0.8250726427242254\n",
      "Train loss: 0.9315003608442416\n",
      "Train loss: 1.4045901177035776\n",
      "Train loss: 0.5085094958353954\n",
      "Train loss: 0.7923745361103374\n",
      "Train loss: 0.8632507863318085\n",
      "Train loss: 0.5996925424618326\n",
      "Train loss: 0.29769950459717187\n",
      "Train loss: 0.6822053456002739\n",
      "Train loss: 0.3885033157221071\n",
      "\n",
      "Test set: Avg. loss: 0.0004146324098110199, AUC: 0.911088\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003962185829877853, AUC: 0.928681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038269555568695067, AUC: 0.9335709999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006918051838874817, AUC: 0.6078685\n",
      "\n",
      "Train loss: 1.556321721547728\n",
      "Train loss: 1.3116541933861507\n",
      "Train loss: 1.3728186195823038\n",
      "Train loss: 1.1807150051092645\n",
      "Train loss: 1.3282080304091144\n",
      "Train loss: 1.1629292068967394\n",
      "Train loss: 1.155078321505504\n",
      "Train loss: 1.1272341271114956\n",
      "Train loss: 0.7945121223000204\n",
      "Train loss: 0.8294190396169189\n",
      "Train loss: 0.9098578072657251\n",
      "Train loss: 0.7372154377068684\n",
      "Train loss: 0.8778107838266215\n",
      "Train loss: 0.7533023596569232\n",
      "Train loss: 0.5721017201994635\n",
      "\n",
      "Test set: Avg. loss: 0.0004253978282213211, AUC: 0.912493\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00040360434353351593, AUC: 0.92855\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003604414016008377, AUC: 0.939916\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006946688294410706, AUC: 0.5203519999999999\n",
      "\n",
      "Train loss: 2.583174364961636\n",
      "Train loss: 2.4968437822001754\n",
      "Train loss: 2.1837105314443064\n",
      "Train loss: 1.967260580533629\n",
      "Train loss: 2.103243129268573\n",
      "Train loss: 1.9119337064445399\n",
      "Train loss: 2.0439731125619\n",
      "Train loss: 2.4246411581707608\n",
      "Train loss: 1.7226149785290858\n",
      "Train loss: 1.8757968374118683\n",
      "Train loss: 1.873263371598189\n",
      "Train loss: 1.6292909531836297\n",
      "Train loss: 1.47985786009746\n",
      "Train loss: 1.4492073017320815\n",
      "Train loss: 1.815670432558485\n",
      "\n",
      "Test set: Avg. loss: 0.00045680414140224457, AUC: 0.8966700000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00040216045081615447, AUC: 0.91575\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00041600202023983, AUC: 0.9249080000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006985277235507965, AUC: 0.320307\n",
      "\n",
      "Train loss: 2.4310016673841295\n",
      "Train loss: 1.9460211449367986\n",
      "Train loss: 2.304060568095772\n",
      "Train loss: 1.7767846922206272\n",
      "Train loss: 1.9375786413053038\n",
      "Train loss: 1.9003502024207146\n",
      "Train loss: 1.4759956632450129\n",
      "Train loss: 1.5016104552396543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.970422636551462\n",
      "Train loss: 1.4079155132269403\n",
      "Train loss: 1.4688413837912735\n",
      "Train loss: 1.4076758281440491\n",
      "Train loss: 1.1350592856953858\n",
      "Train loss: 1.8857001426872935\n",
      "Train loss: 1.4556400149491182\n",
      "\n",
      "Test set: Avg. loss: 0.00047363899648189545, AUC: 0.8819830000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042409318685531617, AUC: 0.908577\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003766205757856369, AUC: 0.922854\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006900011897087098, AUC: 0.654073\n",
      "\n",
      "Train loss: 1.9343711790765168\n",
      "Train loss: 1.4965036446881141\n",
      "Train loss: 1.744480819459174\n",
      "Train loss: 1.445263187217105\n",
      "Train loss: 1.3542424216391935\n",
      "Train loss: 1.3084997363910553\n",
      "Train loss: 1.4788874330793975\n",
      "Train loss: 1.3785485469611587\n",
      "Train loss: 1.6266570197548835\n",
      "Train loss: 1.6530657175240244\n",
      "Train loss: 1.117041161105891\n",
      "Train loss: 1.1217445317347339\n",
      "Train loss: 0.7305867747896037\n",
      "Train loss: 1.335534641317501\n",
      "Train loss: 1.165849501539947\n",
      "\n",
      "Test set: Avg. loss: 0.0004729681611061096, AUC: 0.886551\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000434605211019516, AUC: 0.9089720000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003964823633432388, AUC: 0.921496\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006948385834693909, AUC: 0.45293300000000003\n",
      "\n",
      "Train loss: 2.838434695438215\n",
      "Train loss: 2.1438076230371075\n",
      "Train loss: 2.4100869370114273\n",
      "Train loss: 2.3277919983408255\n",
      "Train loss: 2.0542441857088902\n",
      "Train loss: 1.932898898413227\n",
      "Train loss: 2.1418099612187427\n",
      "Train loss: 1.8697841486353783\n",
      "Train loss: 1.4413236861775636\n",
      "Train loss: 1.176063375108561\n",
      "Train loss: 1.573230844014769\n",
      "Train loss: 1.1145322140614697\n",
      "Train loss: 1.1721717271075887\n",
      "Train loss: 1.6871109627614356\n",
      "Train loss: 1.3137204996339835\n",
      "\n",
      "Test set: Avg. loss: 0.00045576393604278563, AUC: 0.8993240000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004253361374139786, AUC: 0.9163030000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004524254947900772, AUC: 0.921484\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000694339007139206, AUC: 0.44818199999999997\n",
      "\n",
      "Train loss: 1.902850356071618\n",
      "Train loss: 1.9377130387694972\n",
      "Train loss: 1.8242057926335913\n",
      "Train loss: 1.501140846568308\n",
      "Train loss: 1.5635184444439638\n",
      "Train loss: 1.494578115499703\n",
      "Train loss: 1.3114372070427913\n",
      "Train loss: 0.984448684628602\n",
      "Train loss: 1.0118428742050365\n",
      "Train loss: 1.2679768876664956\n",
      "Train loss: 0.9874832296067741\n",
      "Train loss: 0.8487269920148667\n",
      "Train loss: 0.9704973014296999\n",
      "Train loss: 1.1202531449354378\n",
      "Train loss: 0.8656843410935372\n",
      "\n",
      "Test set: Avg. loss: 0.00047323435544967653, AUC: 0.8815930000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004198194146156311, AUC: 0.9080090000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000403200775384903, AUC: 0.9177559999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006985858380794526, AUC: 0.402578\n",
      "\n",
      "Train loss: 1.5185066909547065\n",
      "Train loss: 1.303605723912549\n",
      "Train loss: 1.3999682611720576\n",
      "Train loss: 1.5271335122691598\n",
      "Train loss: 1.525771030574847\n",
      "Train loss: 1.2952381581257864\n",
      "Train loss: 1.81612629875256\n",
      "Train loss: 1.8068520772229335\n",
      "Train loss: 1.4788496224743546\n",
      "Train loss: 1.3772668880262193\n",
      "Train loss: 1.2112371359661127\n",
      "Train loss: 0.9699833267813276\n",
      "Train loss: 1.3372103283359746\n",
      "Train loss: 1.5658973444039654\n",
      "Train loss: 1.0090744294178713\n",
      "\n",
      "Test set: Avg. loss: 0.00046936610341072083, AUC: 0.8861859999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00040863730013370516, AUC: 0.908681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000389703094959259, AUC: 0.923539\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007027014195919037, AUC: 0.44139599999999996\n",
      "\n",
      "Train loss: 4.961532285638675\n",
      "Train loss: 3.8456980422803553\n",
      "Train loss: 3.822131424572817\n",
      "Train loss: 4.261773332668717\n",
      "Train loss: 3.214836978988283\n",
      "Train loss: 2.9650693087820796\n",
      "Train loss: 3.557798695032764\n",
      "Train loss: 2.7855322319231215\n",
      "Train loss: 2.490268556175718\n",
      "Train loss: 3.0649039604861263\n",
      "Train loss: 2.4456994996708668\n",
      "Train loss: 3.189392985052364\n",
      "Train loss: 2.502088221774739\n",
      "Train loss: 2.5820756550807102\n",
      "Train loss: 2.505756460557318\n",
      "\n",
      "Test set: Avg. loss: 0.0004634280651807785, AUC: 0.883039\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044609998166561125, AUC: 0.900667\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042397844791412353, AUC: 0.91744\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006935093700885772, AUC: 0.4911545\n",
      "\n",
      "Train loss: 2.827882004771263\n",
      "Train loss: 2.7604078304995396\n",
      "Train loss: 1.9118825762894502\n",
      "Train loss: 1.9576757216149834\n",
      "Train loss: 1.6423242198433845\n",
      "Train loss: 1.9774705266496937\n",
      "Train loss: 2.4156057853607615\n",
      "Train loss: 1.8582306766206291\n",
      "Train loss: 2.2600067265474113\n",
      "Train loss: 1.7889438856179547\n",
      "Train loss: 2.1400705929015094\n",
      "Train loss: 1.664519857828784\n",
      "Train loss: 2.3582702047505957\n",
      "Train loss: 1.7632667574153584\n",
      "Train loss: 1.589283303850016\n",
      "\n",
      "Test set: Avg. loss: 0.00048163852095603943, AUC: 0.881441\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004130743741989136, AUC: 0.910871\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00039782479405403137, AUC: 0.916774\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006909832954406738, AUC: 0.6436289999999999\n",
      "\n",
      "Train loss: 2.4274699498134056\n",
      "Train loss: 1.4709733443655026\n",
      "Train loss: 2.585436264800418\n",
      "Train loss: 1.9941132322997803\n",
      "Train loss: 2.0299238835930065\n",
      "Train loss: 1.449279988267619\n",
      "Train loss: 1.4882808225170063\n",
      "Train loss: 1.4821608377869722\n",
      "Train loss: 1.3700888042996644\n",
      "Train loss: 1.6339233369584296\n",
      "Train loss: 1.4365667962724236\n",
      "Train loss: 1.3266162739437857\n",
      "Train loss: 1.1601651132486428\n",
      "Train loss: 1.2700066080518588\n",
      "Train loss: 1.5300845682241355\n",
      "\n",
      "Test set: Avg. loss: 0.0004493151754140854, AUC: 0.902361\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004268527626991272, AUC: 0.9176790000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038585835695266723, AUC: 0.927446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006962308585643769, AUC: 0.6114605000000001\n",
      "\n",
      "Train loss: 2.139595368485542\n",
      "Train loss: 2.0107818059860523\n",
      "Train loss: 2.4498375403653285\n",
      "Train loss: 2.31513741593452\n",
      "Train loss: 1.9138831143166608\n",
      "Train loss: 2.1946495889098783\n",
      "Train loss: 1.992693810705926\n",
      "Train loss: 1.549981985122535\n",
      "Train loss: 1.459531976918506\n",
      "Train loss: 1.66401763744415\n",
      "Train loss: 1.7735859170840804\n",
      "Train loss: 1.8173054764225225\n",
      "Train loss: 1.778051620456064\n",
      "Train loss: 1.4682476342104043\n",
      "Train loss: 1.7584255197245604\n",
      "\n",
      "Test set: Avg. loss: 0.0004657865762710571, AUC: 0.8844319999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00041551969945430756, AUC: 0.9141600000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003932972252368927, AUC: 0.924954\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006947956979274749, AUC: 0.5016995\n",
      "\n",
      "Train loss: 1.3341237105381716\n",
      "Train loss: 2.1974878618671636\n",
      "Train loss: 2.050501252435575\n",
      "Train loss: 1.7039758794626612\n",
      "Train loss: 1.8012874642754817\n",
      "Train loss: 1.9536826815574793\n",
      "Train loss: 1.3181599283673961\n",
      "Train loss: 1.7080981807344278\n",
      "Train loss: 1.522159779907032\n",
      "Train loss: 1.818768725653363\n",
      "Train loss: 1.471985999565975\n",
      "Train loss: 1.7699677932793927\n",
      "Train loss: 1.500324511983592\n",
      "Train loss: 1.3309327329799627\n",
      "Train loss: 1.5362904292003365\n",
      "\n",
      "Test set: Avg. loss: 0.00041811206936836245, AUC: 0.906908\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00039508455991744994, AUC: 0.9253369999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003738473653793335, AUC: 0.9314579999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006912962794303894, AUC: 0.5875945\n",
      "\n",
      "Train loss: 2.5562263715798688\n",
      "Train loss: 2.054924303179334\n",
      "Train loss: 2.067889763671122\n",
      "Train loss: 1.733651000982637\n",
      "Train loss: 1.9267696768614897\n",
      "Train loss: 1.7586761895258716\n",
      "Train loss: 1.8657160644318647\n",
      "Train loss: 1.719739404073946\n",
      "Train loss: 1.5096439312977397\n",
      "Train loss: 1.4931185518860057\n",
      "Train loss: 1.6661030832369617\n",
      "Train loss: 1.2818263689423823\n",
      "Train loss: 1.7293831174540673\n",
      "Train loss: 1.5203613369328202\n",
      "Train loss: 1.7941524568636706\n",
      "\n",
      "Test set: Avg. loss: 0.0004423072338104248, AUC: 0.9094360000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000423960343003273, AUC: 0.9248050000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038462673127651216, AUC: 0.9346629999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006945312023162841, AUC: 0.5326005\n",
      "\n",
      "Train loss: 1.7690215634692246\n",
      "Train loss: 1.4092736794690417\n",
      "Train loss: 1.6899825239637096\n",
      "Train loss: 1.542519234547949\n",
      "Train loss: 1.5543991391825829\n",
      "Train loss: 1.7196540612324027\n",
      "Train loss: 1.6057658928215124\n",
      "Train loss: 1.3434792328032719\n",
      "Train loss: 1.5152052048664943\n",
      "Train loss: 1.0969433978105048\n",
      "Train loss: 1.7800151591847657\n",
      "Train loss: 1.3823064265737108\n",
      "Train loss: 1.6685189483272043\n",
      "Train loss: 1.069920779033831\n",
      "Train loss: 0.9663466355603212\n",
      "\n",
      "Test set: Avg. loss: 0.0004216569662094116, AUC: 0.9140440000000001\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.00036962753534317016, AUC: 0.9312050000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004138304591178894, AUC: 0.9353440000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000701473593711853, AUC: 0.40515\n",
      "\n",
      "Train loss: 1.065467907744608\n",
      "Train loss: 1.3622498276886668\n",
      "Train loss: 1.5146699308589766\n",
      "Train loss: 1.1519298059925152\n",
      "Train loss: 1.2872650144965785\n",
      "Train loss: 1.1337903233090783\n",
      "Train loss: 1.0842262722884015\n",
      "Train loss: 1.1602510191073083\n",
      "Train loss: 0.7593976547763606\n",
      "Train loss: 1.2732060164403005\n",
      "Train loss: 1.3662886513266594\n",
      "Train loss: 0.6023548021438015\n",
      "Train loss: 1.124361228791012\n",
      "Train loss: 1.1234989906572233\n",
      "Train loss: 0.8597518346112245\n",
      "\n",
      "Test set: Avg. loss: 0.00041623535752296446, AUC: 0.920745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003963103443384171, AUC: 0.934286\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00045862875878810883, AUC: 0.936785\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006941128373146058, AUC: 0.5132665\n",
      "\n",
      "Train loss: 3.3644635339451443\n",
      "Train loss: 2.1163280215232994\n",
      "Train loss: 1.979751812044982\n",
      "Train loss: 2.9655603694308335\n",
      "Train loss: 2.335901003354674\n",
      "Train loss: 2.091515109037897\n",
      "Train loss: 2.206679254200808\n",
      "Train loss: 2.734819473734327\n",
      "Train loss: 1.8713578969050364\n",
      "Train loss: 2.6784692695186396\n",
      "Train loss: 1.6861833098587717\n",
      "Train loss: 1.3730688007773868\n",
      "Train loss: 1.534634741628246\n",
      "Train loss: 0.7286027252294456\n",
      "Train loss: 1.3139150590653632\n",
      "\n",
      "Test set: Avg. loss: 0.00042359192669391634, AUC: 0.9082400000000002\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00048334313929080964, AUC: 0.9193760000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044934698939323427, AUC: 0.928472\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000695196270942688, AUC: 0.5298175\n",
      "\n",
      "Train loss: 3.044659461944726\n",
      "Train loss: 2.551771532957721\n",
      "Train loss: 1.9014595355957178\n",
      "Train loss: 2.7509314641831026\n",
      "Train loss: 2.764628359086954\n",
      "Train loss: 2.745275926438107\n",
      "Train loss: 1.9674844369766817\n",
      "Train loss: 2.536965831449837\n",
      "Train loss: 2.5107981592986235\n",
      "Train loss: 2.899844480927583\n",
      "Train loss: 1.9817434936572031\n",
      "Train loss: 2.260456234786161\n",
      "Train loss: 1.6879900371193126\n",
      "Train loss: 1.92731064140417\n",
      "Train loss: 1.6755265346757926\n",
      "\n",
      "Test set: Avg. loss: 0.00039330087602138517, AUC: 0.9168320000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035143940150737763, AUC: 0.9378569999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00034264783561229704, AUC: 0.9414929999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000689552366733551, AUC: 0.6212285\n",
      "\n",
      "Train loss: 1.5331814262517698\n",
      "Train loss: 1.1389007648085332\n",
      "Train loss: 1.0991159210539168\n",
      "Train loss: 1.3965047176476497\n",
      "Train loss: 1.4320910075667557\n",
      "Train loss: 1.1398993722952095\n",
      "Train loss: 1.6438671938932625\n",
      "Train loss: 1.4221151881157212\n",
      "Train loss: 1.2001555311452052\n",
      "Train loss: 1.0746287483318595\n",
      "Train loss: 1.1720936499583494\n",
      "Train loss: 0.8358631714893754\n",
      "Train loss: 1.1796302647347663\n",
      "Train loss: 1.10521779318524\n",
      "Train loss: 0.7776804186735943\n",
      "\n",
      "Test set: Avg. loss: 0.00048428669571876526, AUC: 0.9118379999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0005237846672534942, AUC: 0.9262415\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000569075345993042, AUC: 0.930221\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007029748857021331, AUC: 0.322977\n",
      "\n",
      "Train loss: 1.605328872325314\n",
      "Train loss: 1.5588653919043813\n",
      "Train loss: 1.9121351648288167\n",
      "Train loss: 1.7227350234226058\n",
      "Train loss: 2.212599135128556\n",
      "Train loss: 1.6610165314309915\n",
      "Train loss: 1.7295450454304933\n",
      "Train loss: 1.3934827670929537\n",
      "Train loss: 1.5008799915860414\n",
      "Train loss: 1.5810198168845693\n",
      "Train loss: 1.446541486652034\n",
      "Train loss: 1.4180493168770127\n",
      "Train loss: 1.4187206899284557\n",
      "Train loss: 1.3737571755791926\n",
      "Train loss: 1.5052037675669239\n",
      "\n",
      "Test set: Avg. loss: 0.000428346574306488, AUC: 0.9038660000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000408862441778183, AUC: 0.918464\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003745451718568802, AUC: 0.9323959999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006958560943603516, AUC: 0.421932\n",
      "\n",
      "Train loss: 2.002201202948382\n",
      "Train loss: 2.4418856721774787\n",
      "Train loss: 1.9039164796756332\n",
      "Train loss: 1.836776056107442\n",
      "Train loss: 1.9867238633951563\n",
      "Train loss: 1.9795862872889087\n",
      "Train loss: 1.8044664111866313\n",
      "Train loss: 2.020744363593448\n",
      "Train loss: 1.4115867785587433\n",
      "Train loss: 1.2793003613022482\n",
      "Train loss: 1.7193037043711183\n",
      "Train loss: 1.0090994785545737\n",
      "Train loss: 1.7226488483939202\n",
      "Train loss: 1.3057370823659715\n",
      "Train loss: 1.5997074652629293\n",
      "\n",
      "Test set: Avg. loss: 0.00039876195788383483, AUC: 0.911627\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000370293989777565, AUC: 0.932272\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042317914962768555, AUC: 0.9371469999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006970470249652862, AUC: 0.361263\n",
      "\n",
      "Train loss: 1.448426442920782\n",
      "Train loss: 2.0261547238963424\n",
      "Train loss: 1.500613168925996\n",
      "Train loss: 1.696548611874793\n",
      "Train loss: 1.26298499524973\n",
      "Train loss: 1.4457258775735358\n",
      "Train loss: 1.8663959533545622\n",
      "Train loss: 1.6790762638590138\n",
      "Train loss: 1.311977691331487\n",
      "Train loss: 1.110382558433873\n",
      "Train loss: 1.3031481622131007\n",
      "Train loss: 1.2095687112231164\n",
      "Train loss: 1.3323279623013393\n",
      "Train loss: 1.1119391310746503\n",
      "Train loss: 1.1362310928903567\n",
      "\n",
      "Test set: Avg. loss: 0.00042390996217727664, AUC: 0.9123509999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0004404672384262085, AUC: 0.9210309999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00038320353627204894, AUC: 0.933745\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006908539235591888, AUC: 0.6276575\n",
      "\n",
      "Train loss: 2.2480395626110634\n",
      "Train loss: 1.1867681301323472\n",
      "Train loss: 1.4849141137615132\n",
      "Train loss: 1.362275172950356\n",
      "Train loss: 0.8740834548215198\n",
      "Train loss: 1.0733056269633543\n",
      "Train loss: 0.8760471575579066\n",
      "Train loss: 1.1791387845756143\n",
      "Train loss: 0.5943953797316096\n",
      "Train loss: 0.9012027902967611\n",
      "Train loss: 0.719067598604093\n",
      "Train loss: 0.780088439868514\n",
      "Train loss: 0.5790081627809318\n",
      "Train loss: 0.4776619718332959\n",
      "Train loss: 0.4154877954987204\n",
      "\n",
      "Test set: Avg. loss: 0.00033546756207942965, AUC: 0.9382889999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035798951983451844, AUC: 0.937374\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00032517361640930175, AUC: 0.946767\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006927938163280487, AUC: 0.5568995000000001\n",
      "\n",
      "Train loss: 1.4981148956687587\n",
      "Train loss: 1.2609440695707965\n",
      "Train loss: 1.2108171726488004\n",
      "Train loss: 1.0813258818000744\n",
      "Train loss: 1.2218539077005568\n",
      "Train loss: 0.7958241264531567\n",
      "Train loss: 0.8111746523790299\n",
      "Train loss: 0.8097322211144077\n",
      "Train loss: 0.8614113258708055\n",
      "Train loss: 0.7558070451590666\n",
      "Train loss: 0.5925567305771409\n",
      "Train loss: 0.4964767675490896\n",
      "Train loss: 0.6136222743684319\n",
      "Train loss: 0.4303761568798381\n",
      "Train loss: 0.5412341234790292\n",
      "\n",
      "Test set: Avg. loss: 0.00044493715465068816, AUC: 0.931014\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035282617807388304, AUC: 0.9393670000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037601666152477264, AUC: 0.9394140000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006940064132213593, AUC: 0.46464300000000003\n",
      "\n",
      "Train loss: 1.6525405337856074\n",
      "Train loss: 1.4180748227295603\n",
      "Train loss: 1.3354255849388754\n",
      "Train loss: 0.9160423806518506\n",
      "Train loss: 1.1159068854751102\n",
      "Train loss: 1.023386694823101\n",
      "Train loss: 0.7024036383932564\n",
      "Train loss: 0.5737391129420821\n",
      "Train loss: 0.5905510122608987\n",
      "Train loss: 0.5709847253598984\n",
      "Train loss: 0.8043206990904109\n",
      "Train loss: 0.740040373650326\n",
      "Train loss: 0.6739116941288019\n",
      "Train loss: 0.6548642819854105\n",
      "Train loss: 0.5283254354622713\n",
      "\n",
      "Test set: Avg. loss: 0.00042415910959243773, AUC: 0.931735\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.000426410436630249, AUC: 0.918856\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003601570874452591, AUC: 0.9355960000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006934064030647278, AUC: 0.5043955\n",
      "\n",
      "Train loss: 2.4910039184199775\n",
      "Train loss: 1.39337097307679\n",
      "Train loss: 1.7959011645074103\n",
      "Train loss: 1.5066651326076241\n",
      "Train loss: 1.3483489721444002\n",
      "Train loss: 1.2652093870624614\n",
      "Train loss: 1.0816131784657763\n",
      "Train loss: 1.0603626484324218\n",
      "Train loss: 1.095256202919468\n",
      "Train loss: 0.9734524534006787\n",
      "Train loss: 0.8608164954337345\n",
      "Train loss: 0.6773723485363516\n",
      "Train loss: 0.7821790982203879\n",
      "Train loss: 0.8961417135918975\n",
      "Train loss: 0.6812320074458031\n",
      "\n",
      "Test set: Avg. loss: 0.0003696085661649704, AUC: 0.9272989999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00034005193412303924, AUC: 0.9373729999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0002953743636608124, AUC: 0.9536279999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006980240941047668, AUC: 0.370317\n",
      "\n",
      "Train loss: 2.6104741016770623\n",
      "Train loss: 1.8149374275450494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9346731878389978\n",
      "Train loss: 1.5430769199019025\n",
      "Train loss: 1.4607565668737812\n",
      "Train loss: 1.393643997277424\n",
      "Train loss: 1.3211874517665547\n",
      "Train loss: 0.921329250381251\n",
      "Train loss: 0.9669004671133248\n",
      "Train loss: 0.9917047209800429\n",
      "Train loss: 0.7282513793866345\n",
      "Train loss: 1.0467327958459307\n",
      "Train loss: 0.5617396865680719\n",
      "Train loss: 0.876054488929214\n",
      "Train loss: 0.6982500355714446\n",
      "\n",
      "Test set: Avg. loss: 0.00039860232174396515, AUC: 0.9290079999999998\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00047183363139629365, AUC: 0.937491\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00032021838426589963, AUC: 0.948357\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006923727095127105, AUC: 0.5628065\n",
      "\n",
      "Train loss: 1.5512303265796346\n",
      "Train loss: 1.2353783249855042\n",
      "Train loss: 1.1475682938174836\n",
      "Train loss: 1.4969956195278533\n",
      "Train loss: 0.979395692515525\n",
      "Train loss: 1.053526867726806\n",
      "Train loss: 0.7830445409580401\n",
      "Train loss: 0.7794080646174728\n",
      "Train loss: 0.9118682161258285\n",
      "Train loss: 0.7145632490230973\n",
      "Train loss: 0.9021045573198112\n",
      "Train loss: 0.6404331132864497\n",
      "Train loss: 0.5584030967609138\n",
      "Train loss: 0.7357639848806297\n",
      "Train loss: 0.4938939783223875\n",
      "\n",
      "Test set: Avg. loss: 0.0003621644228696823, AUC: 0.934321\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00037211982905864717, AUC: 0.93608\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003810114860534668, AUC: 0.941255\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006943982541561126, AUC: 0.56987\n",
      "\n",
      "Train loss: 1.6806978336565055\n",
      "Train loss: 1.7956415847608238\n",
      "Train loss: 1.5534688940473422\n",
      "Train loss: 1.389758839728726\n",
      "Train loss: 1.3698183427191084\n",
      "Train loss: 0.8360725580507024\n",
      "Train loss: 1.1988897866504207\n",
      "Train loss: 0.9091258352729166\n",
      "Train loss: 1.045509720683857\n",
      "Train loss: 0.7474547100674575\n",
      "Train loss: 1.0273564533822854\n",
      "Train loss: 0.6318259064558964\n",
      "Train loss: 0.5475991782109448\n",
      "Train loss: 0.818452742828685\n",
      "Train loss: 0.627023975940267\n",
      "\n",
      "Test set: Avg. loss: 0.0004389137625694275, AUC: 0.9327400000000001\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003822837918996811, AUC: 0.946448\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003276159167289734, AUC: 0.951301\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006927377581596374, AUC: 0.574253\n",
      "\n",
      "Train loss: 1.5772852950794682\n",
      "Train loss: 1.4025484095713137\n",
      "Train loss: 1.0292934209677824\n",
      "Train loss: 1.5213698274011065\n",
      "Train loss: 0.6666313500920679\n",
      "Train loss: 0.7515288648332\n",
      "Train loss: 0.6539147727808375\n",
      "Train loss: 0.7053451397616393\n",
      "Train loss: 0.6444514397602932\n",
      "Train loss: 0.7410922954036931\n",
      "Train loss: 0.7267304210905816\n",
      "Train loss: 0.5181050441067689\n",
      "Train loss: 0.375660929330595\n",
      "Train loss: 0.4891196352661036\n",
      "Train loss: 0.5434732213141812\n",
      "\n",
      "Test set: Avg. loss: 0.0003837060332298279, AUC: 0.936681\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003397395610809326, AUC: 0.946446\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00042534206807613375, AUC: 0.9451959999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0006931170523166657, AUC: 0.5075235\n",
      "\n",
      "Train loss: 2.0237746056477737\n",
      "Train loss: 1.169994580897556\n",
      "Train loss: 1.530900303345577\n",
      "Train loss: 1.593341377890034\n",
      "Train loss: 1.4924902593254283\n",
      "Train loss: 0.9746312905269064\n",
      "Train loss: 1.018703309973334\n",
      "Train loss: 1.0353986256441492\n",
      "Train loss: 0.9771102123959049\n",
      "Train loss: 0.7796362034834114\n",
      "Train loss: 0.4925922064264868\n",
      "Train loss: 0.7538846028838188\n",
      "Train loss: 0.6389873692184497\n",
      "Train loss: 0.5430046456634618\n",
      "Train loss: 0.5402585753969326\n",
      "\n",
      "Test set: Avg. loss: 0.00037191537022590636, AUC: 0.932969\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003247491419315338, AUC: 0.9419019999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0003453776389360428, AUC: 0.9490419999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.0007015862166881562, AUC: 0.3505795\n",
      "\n",
      "Train loss: 3.9646280768570628\n",
      "Train loss: 3.3033991725581466\n",
      "Train loss: 2.5725907102511947\n",
      "Train loss: 1.376922410005217\n",
      "Train loss: 1.9258307036320874\n",
      "Train loss: 1.2071792749082966\n",
      "Train loss: 1.3905717703946836\n",
      "Train loss: 1.1171147922042068\n",
      "Train loss: 1.085816380324637\n",
      "Train loss: 1.1823566867287751\n",
      "Train loss: 1.0678503915762445\n",
      "Train loss: 0.7482025319603598\n",
      "Train loss: 0.6341669468363379\n",
      "Train loss: 1.255767916418185\n",
      "Train loss: 0.7214999483649138\n",
      "\n",
      "Test set: Avg. loss: 0.00038818895816802976, AUC: 0.932067\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00035361112654209135, AUC: 0.9387269999999999\n",
      "\n",
      "\n",
      "Test set: Avg. loss: 0.00044564680755138395, AUC: 0.9421510000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 class triplet loss no ratio \n",
    "# no smote \n",
    "\n",
    "\n",
    "momentum=0\n",
    "learning_rates = [(5e-6, 1e-2), (1e-6, 5e-3), (1e-6, 1e-2), (5e-6, 5e-2)]\n",
    "\n",
    "learning_rate_aucs = []\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    aucs = []\n",
    "    for i in range(10): \n",
    "        model_aucs = []\n",
    "        embed_network = models.ConvNetOnlyEmbeddingsEarly(2)\n",
    "        linear_probe = models.ConvNetLinearProbeEarly(2)\n",
    "        complete_network = models.CompleteConvNet(embed_network, linear_probe)\n",
    "        embed_optimizer = optim.SGD(embed_network.parameters(), lr=learning_rate[0], momentum=momentum)\n",
    "        linear_optimizer = optim.SGD(complete_network.parameters(), lr=learning_rate[1], momentum=momentum)\n",
    "        _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True) \n",
    "        model_aucs.append(auc)\n",
    "        for epoch in range(15):\n",
    "            _, train_losses = train.train_triplet_loss(epoch, train_loader_tripletloss, embed_network, embed_optimizer, verbose=False)\n",
    "            print(\"Train loss: \" + str(np.mean(np.array(train_losses))))\n",
    "        for epoch in range(n_epochs):\n",
    "            _, _ = train.train_sigmoid(epoch, train_loader_reduced, complete_network, linear_optimizer, verbose=False)\n",
    "            if (epoch + 1) % 10 == 0: \n",
    "                _, auc = metric_utils.auc_sigmoid(test_loader_reduced, complete_network, embeddings=True)\n",
    "                model_aucs.append(auc) \n",
    "        aucs.append(model_aucs)\n",
    "    learning_rate_aucs.append(aucs)\n",
    "    \n",
    "learning_rate_aucs = np.asarray(learning_rate_aucs)\n",
    "\n",
    "auc_mean = np.mean(learning_rate_aucs, axis=1)\n",
    "auc_variance = np.var(learning_rate_aucs, axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(learning_rates)): \n",
    "    row = [\"triplet_loss\", 2, nums, (1, 1), learning_rates[i],\n",
    "            auc_mean[i][0], auc_variance[i][0], \n",
    "            auc_mean[i][1], auc_variance[i][1],\n",
    "            auc_mean[i][2], auc_variance[i][2],\n",
    "            auc_mean[i][3], auc_variance[i][3], None, norm, None]\n",
    "    rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82f0b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('results/convnet_early_tripletloss_aucs.csv')\n",
    "\n",
    "df2 = pd.DataFrame(rows, columns = col_names) \n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('results/convnet_early_tripletloss_aucs.csv', index=False)\n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c195e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7452fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
