{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "from warnings import simplefilter\n",
    "import pandas as pd\n",
    "import ast\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f29c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results/convnet_aucs.csv')\n",
    "# use results/cleaned_convent_aucs.csv instead to find best results/data being used in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ratio = df.ratio.apply(lambda x : ast.literal_eval(x))\n",
    "df.classes_used = df.classes_used.apply(lambda x : ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb4548",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (100, 1) \n",
    "norm = False\n",
    "\n",
    "NUM_CLASSES= len(ratio)\n",
    "\n",
    "normal_df = df.loc[(df.name=='normal') & (df.num_classes==NUM_CLASSES) & (df.normalization==norm)]\n",
    "ratio_df = df.loc[(df.name=='ratio') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "oversampled_df = df.loc[(df.name=='oversampled') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "weighted_df = df.loc[(df.name=='weighted') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "undersampled_df = df.loc[(df.name=='undersampled') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "\n",
    "smote_df = df.loc[(df.name=='smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "\n",
    "capped_smote10_df = df.loc[(df.name=='capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.cap==10.0)& (df.normalization==norm)]\n",
    "capped_smote5_df = df.loc[(df.name=='capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.cap==5.0)& (df.normalization==norm)]\n",
    "capped_smote_df = df.loc[(df.name=='capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.cap==1.0)& (df.normalization==norm)]\n",
    "\n",
    "distance_capped_smote_df = df.loc[(df.name=='distance_capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio)& (df.normalization==norm) & (df.cap==1.0)]\n",
    "distance_capped_smote5_df = df.loc[(df.name=='distance_capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio)& (df.normalization==norm) & (df.cap==5.0)]\n",
    "distance_capped_smote10_df = df.loc[(df.name=='distance_capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio)& (df.normalization==norm) & (df.cap==10.0)]\n",
    "\n",
    "\n",
    "cosine_distance_capped_smote_df = df.loc[(df.name=='cosine_distance_capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm) & (df.cap==1.0)]\n",
    "cosine_distance_capped_smote10_df = df.loc[(df.name=='cosine_distance_capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio)& (df.normalization==norm) & (df.cap == 10.0)]\n",
    "cosine_distance_capped_smote5_df = df.loc[(df.name=='cosine_distance_capped_smote') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio)& (df.normalization==norm)& (df.cap == 5.0)]\n",
    "cosine_distance_capped_smote_avg_df = df.loc[(df.name=='cosine_distance_capped_smote_avg') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "cosine_distance_capped_smote_with_triplet_loss_df = df.loc[(df.name=='cosine_distance_capped_smote_with_triplet_loss') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "cosine_distance_capped_smote_with_smote_triplet_loss_df = df.loc[(df.name=='cosine_distance_capped_smote_with_smote_triplet_loss') & (df.num_classes==NUM_CLASSES) & (df.ratio==ratio) & (df.normalization==norm)]\n",
    "\n",
    "\n",
    "triplet_loss_df = df.loc[(df.name=='triplet_loss') & (df.num_classes==NUM_CLASSES)& (df.normalization==norm)]\n",
    "triplet_loss_capped_smote_df = df.loc[(df.name=='triplet_loss_capped_smote') & (df.num_classes==NUM_CLASSES)& (df.ratio==ratio)& (df.normalization==norm) & (df.cap==1.0)]\n",
    "triplet_loss_capped_smote5_df = df.loc[(df.name=='triplet_loss_capped_smote') & (df.num_classes==NUM_CLASSES)& (df.ratio==ratio)& (df.normalization==norm) & (df.cap == 5.0)]\n",
    "triplet_loss_capped_smote10_df = df.loc[(df.name=='triplet_loss_capped_smote') & (df.num_classes==NUM_CLASSES)& (df.ratio==ratio)& (df.normalization==norm) & (df.cap==10.0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afbb7b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_rows=[]\n",
    "\n",
    "epochs = [0, 10, 20, 30]\n",
    "mean_cols = [\"mean_\" + str(epoch )for epoch in epochs]\n",
    "variance_cols = [\"variance_\" + str(epoch )for epoch in epochs]\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in normal_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "best_rows.append(best_row)\n",
    "plt.title(\"Normal\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in ratio_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "best_rows.append(best_row)\n",
    "plt.title(str(row['ratio']) + \" Ratio\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in oversampled_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "best_rows.append(best_row)\n",
    "plt.title(str(row['ratio']) + \" Oversampling\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in undersampled_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "best_rows.append(best_row)\n",
    "plt.title(str(row['ratio']) + \" Undersampling\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in weighted_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "best_rows.append(best_row)\n",
    "plt.title(str(row['ratio']) + \" Weighted Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in smote_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "best_rows.append(best_row)\n",
    "plt.title(str(row['ratio']) + \" SMOTE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in capped_smote10_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Cap 10 SMOTE\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '10'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in capped_smote5_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Cap 5 SMOTE\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '5'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in capped_smote_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Cap 1 SMOTE\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '1'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in distance_capped_smote_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Euclidean Distance\")\n",
    "if len(best_row) > 0:    \n",
    "    best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in distance_capped_smote5_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Euclidean Distance (5)\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '5'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in distance_capped_smote10_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Euclidean Distance (10)\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '10'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in cosine_distance_capped_smote_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Cosine Distance\")\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in cosine_distance_capped_smote5_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Cosine Distance (5)\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '5'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in cosine_distance_capped_smote10_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Cosine Distance (10)\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '10'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in cosine_distance_capped_smote_avg_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Cosine Distance Average\")\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in cosine_distance_capped_smote_with_smote_triplet_loss_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Cosine Distance Average and SMOTE Triplet Loss\")\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in cosine_distance_capped_smote_with_triplet_loss_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE with Cosine Distance Average and Triplet Loss\")\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in triplet_loss_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(\"Triplet Loss (no ratio)\")\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in triplet_loss_capped_smote_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE Using Triplet Loss\")\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in triplet_loss_capped_smote5_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE Using Triplet Loss (5)\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '5'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_mean=0\n",
    "best_row = pd.core.series.Series()\n",
    "for index, row in triplet_loss_capped_smote10_df.iterrows(): \n",
    "    means = [row[mean_name] for mean_name in mean_cols]\n",
    "    variances = [row[variance] for variance in variance_cols]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=row['learning_rate'])\n",
    "    if row[mean_cols[-1]] >= best_mean: \n",
    "        best_row = row\n",
    "        best_mean=row[mean_cols[-1]]\n",
    "    plt.title(str(row['ratio']) + \" Capped SMOTE Using Triplet Loss (10)\")\n",
    "if len(best_row) > 0:\n",
    "    best_row['name'] = best_row['name'] + '10'\n",
    "best_rows.append(best_row)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13677178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# narrow down which data to graph \n",
    "\n",
    "rows_to_graph = ['normal', 'ratio', 'oversampled', 'undersampled', 'weighted']\n",
    "# rows_to_graph = ['smote', 'capped_smote1', 'capped_smote5', 'capped_smote10']\n",
    "# rows_to_graph = ['smote', 'distance_capped_smote5', 'cosine_distance_capped_smote', 'cosine_distance_capped_smote5', 'cosine_distance_capped_smote_avg']\n",
    "# rows_to_graph = ['smote', 'triplet_loss_capped_smote5', 'cosine_distance_capped_smote_with_triplet_loss', 'cosine_distance_capped_smote_with_smote_triplet_loss']\n",
    "rows_to_graph = ['normal', 'ratio', 'oversampled', 'smote', 'cosine_distance_capped_smote_with_smote_triplet_loss']\n",
    "\n",
    "# rename experiments to appear on graph \n",
    "names = dict(zip(rows_to_graph, rows_to_graph))\n",
    "names['normal'] = 'no class imbalance'\n",
    "names['ratio'] = 'vanilla'\n",
    "names['capped_smote1'] = 'constant capped SMOTE (1)'\n",
    "names['capped_smote5'] = 'constant capped SMOTE (5)'\n",
    "names['capped_smote1'] = 'constant capped SMOTE (10)'\n",
    "names['cosine_distance_capped_smote_avg'] = 'cosine distance capped SMOTE using average tensor'\n",
    "names['cosine_distance_capped_smote_with_triplet_loss'] = 'cosine distance capped SMOTE with triplet loss'\n",
    "names['cosine_distance_capped_smote_with_smote_triplet_loss'] = 'cosine distance capped SMOTE with SMOTE triplet loss'\n",
    "\n",
    "rows = []\n",
    "for row in best_rows:\n",
    "    if (len(row) > 0) and row['name'] in rows_to_graph:\n",
    "        rows.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d9d1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# graphing best AUCs for experiments \n",
    "\n",
    "if NUM_CLASSES == 2:\n",
    "    balanced = (1, 1)\n",
    "elif NUM_CLASSES == 3:\n",
    "    balanced = (1, 1, 1)\n",
    "    \n",
    "for row in rows:\n",
    "    means = [row['mean_' + str(epoch)] for epoch in epochs]\n",
    "    variances = [row['variance_' + str(epoch)] for epoch in epochs]\n",
    "    plt.errorbar(epochs, means, yerr=variances, label=names[row['name']] + \" \" + str(round(max(means), 4)))\n",
    "plt.title(\"Baseline Test AUCs\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1caa4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
